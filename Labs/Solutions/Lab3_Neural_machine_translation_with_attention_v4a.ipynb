{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> 📌 **Avant de commencer :**\n",
        ">\n",
        "> [![Ouvrir dans Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1maaw5EWIzLsGCAhr8klUagld7osI82cy?usp=sharing)\n",
        ">\n",
        "> 🔁 *Veuillez faire une copie dans votre Google Drive (`Fichier > Enregistrer une copie dans Drive`) avant toute modification.*\n"
      ],
      "metadata": {
        "id": "TVIfK1kl_63k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adTDe2CTh3MU"
      },
      "source": [
        "# Traduction Automatique Neuronale\n",
        "\n",
        "Bienvenue dans votre premier devoir de programmation de la semaine !\n",
        "\n",
        "* Vous allez construire un modèle de Traduction Automatique Neuronale (NMT) pour traduire des dates lisibles par l’humain (\"25th of June, 2009\") en dates lisibles par une machine (\"2009-06-25\").\n",
        "* Vous réaliserez cela en utilisant un modèle d’attention, l’un des modèles séquence-à-séquence les plus sophistiqués.\n",
        "\n",
        "Ce notebook a été réalisé en collaboration avec le Deep Learning Institute de NVIDIA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LCkjDBFh3Md"
      },
      "source": [
        "## Table des matières\n",
        "\n",
        "- [Packages](#0)\n",
        "- [1 - Traduction des dates lisibles par l'humain en dates lisibles par la machine](#1)\n",
        "    - [1.1 - Jeu de données](#1-1)\n",
        "- [2 - Traduction automatique neuronale avec attention](#2)\n",
        "    - [2.1 - Mécanisme d'attention](#2-1)\n",
        "        - [Exercice 1 - one_step_attention](#ex-1)\n",
        "        - [Exercice 2 - modelf](#ex-2)\n",
        "        - [Exercice 3 - Compiler le modèle](#ex-3)\n",
        "- [3 - Visualisation de l'attention (Optionnel / Non noté)](#3)\n",
        "    - [3.1 - Obtenir les poids d'attention du réseau](#3-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des paquets"
      ],
      "metadata": {
        "id": "tgMv5UYfu1ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install faker babel tqdm tensorflow transformers datasets evaluate scikit-learn matplotlib\n",
        "! pip install solutions\n",
        "! pip install testCase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQqRLiatu7-x",
        "outputId": "7583f99b-6731-43a6-f60f-f9d440eff472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading faker-37.4.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker, evaluate\n",
            "Successfully installed evaluate-0.4.5 faker-37.4.0\n",
            "Collecting solutions\n",
            "  Downloading solutions-0.0.2.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: solutions\n",
            "  Building wheel for solutions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for solutions: filename=solutions-0.0.2-py3-none-any.whl size=3363 sha256=bf4b2c1a6b3ca9eab72be0f7634640194c6c92d36f3523035c5007b35e742a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/75/b0/5ed63fec747fbdf70606f154524d0e1abb9ec159663c88b516\n",
            "Successfully built solutions\n",
            "Installing collected packages: solutions\n",
            "Successfully installed solutions-0.0.2\n",
            "Collecting testCase\n",
            "  Downloading testcase-0.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading testcase-0.1.0-py3-none-any.whl (2.9 kB)\n",
            "Installing collected packages: testCase\n",
            "Successfully installed testCase-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AG9JuVUa19L"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Importation des paquets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcBRMzPiiMmp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "#from nmt_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import RepeatVector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fonctions**"
      ],
      "metadata": {
        "id": "IM6SQ2TRtwC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateTestCases():\n",
        "\ttestCases = {\n",
        "\t    'one_step_attention': {\n",
        "\t        'partId': 'zcQIs',\n",
        "\t        'testCases': [\n",
        "\t            {\n",
        "\t                'testInput': 0,\n",
        "\t                'testOutput': m_out2\n",
        "\t            }\n",
        "\t        ]\n",
        "\t    },\n",
        "\t    'model': {\n",
        "\t        'partId': 'PTKef',\n",
        "\t        'testCases': [\n",
        "\t            {\n",
        "\t                'testInput': (Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size),\n",
        "\t                'testOutput': m_out1\n",
        "\t            }\n",
        "\t        ]\n",
        "\t    }\n",
        "       }\n",
        "\treturn testCases"
      ],
      "metadata": {
        "id": "nmDnONGtt2F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "Faker.seed(12345)\n",
        "random.seed(12345)\n",
        "\n",
        "# Définir le format des données que nous souhaitons générer\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'd MMM YYY',\n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "# changer cela si vous voulez utiliser une autre langue\n",
        "LOCALES = ['en_US']\n",
        "\n",
        "def load_date():\n",
        "    \"\"\"\n",
        "        Charge quelques dates factices\n",
        "        :returns: tuple contenant la chaîne lisible par l'humain, la chaîne lisible par la machine, et l'objet date\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US')  # locale=random.choice(LOCALES))\n",
        "        human_readable = human_readable.lower()\n",
        "        human_readable = human_readable.replace(',','')\n",
        "        machine_readable = dt.isoformat()\n",
        "\n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt\n",
        "\n",
        "def load_dataset(m):\n",
        "    \"\"\"\n",
        "        Charge un jeu de données avec m exemples et vocabulaires\n",
        "        :m: le nombre d'exemples à générer\n",
        "    \"\"\"\n",
        "\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "    Tx = 30\n",
        "\n",
        "    for i in tqdm(range(m)):\n",
        "        h, m, _ = load_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "\n",
        "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'],\n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        "\n",
        "    return dataset, human, machine, inv_machine\n",
        "\n",
        "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
        "    X, Y = zip(*dataset)\n",
        "\n",
        "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
        "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
        "\n",
        "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
        "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
        "\n",
        "    return X, np.array(Y), Xoh, Yoh\n",
        "\n",
        "def string_to_int(string, length, vocab):\n",
        "    \"\"\"\n",
        "    Convertit toutes les chaînes du vocabulaire en liste d'entiers représentant les positions\n",
        "    des caractères de la chaîne d'entrée dans le vocabulaire \"vocab\".\n",
        "\n",
        "    Arguments:\n",
        "    string -- chaîne d'entrée, par ex. 'Wed 10 Jul 2007'\n",
        "    length -- nombre de pas de temps souhaités, détermine si la sortie sera remplie ou tronquée\n",
        "    vocab -- vocabulaire, dictionnaire utilisé pour indexer chaque caractère de la chaîne\n",
        "\n",
        "    Returns:\n",
        "    rep -- liste d'entiers (ou '<unk>') (taille = length) représentant la position des caractères dans le vocabulaire\n",
        "    \"\"\"\n",
        "\n",
        "    # mise en minuscules pour standardiser\n",
        "    string = string.lower()\n",
        "    string = string.replace(',','')\n",
        "\n",
        "    if len(string) > length:\n",
        "        string = string[:length]\n",
        "\n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "\n",
        "    if len(string) < length:\n",
        "        rep += [vocab['<pad>']] * (length - len(string))\n",
        "\n",
        "    return rep\n",
        "\n",
        "def int_to_string(ints, inv_vocab):\n",
        "    \"\"\"\n",
        "    Produit une liste de caractères lisibles par machine à partir d'une liste d'indices dans le vocabulaire machine.\n",
        "\n",
        "    Arguments:\n",
        "    ints -- liste d'entiers représentant les indices dans le vocabulaire machine\n",
        "    inv_vocab -- dictionnaire mappant les indices aux caractères lisibles par machine\n",
        "\n",
        "    Returns:\n",
        "    l -- liste des caractères correspondant aux indices grâce au mapping inv_vocab\n",
        "    \"\"\"\n",
        "\n",
        "    l = [inv_vocab[i] for i in ints]\n",
        "    return l\n",
        "\n",
        "\n",
        "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
        "        print('entrée :', example)\n",
        "        print('sortie :', predicted[-1])\n",
        "    return predicted\n",
        "\n",
        "\n",
        "def softmax(x, axis=1):\n",
        "    \"\"\"Fonction d'activation softmax.\n",
        "    # Arguments\n",
        "        x : tenseur.\n",
        "        axis: entier, axe selon lequel la normalisation softmax est appliquée.\n",
        "    # Returns\n",
        "        tenseur, sortie de la transformation softmax.\n",
        "    # Raises\n",
        "        ValueError: en cas de tenseur 1D.\n",
        "    \"\"\"\n",
        "    ndim = K.ndim(x)\n",
        "    if ndim == 2:\n",
        "        return K.softmax(x)\n",
        "    elif ndim > 2:\n",
        "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "        s = K.sum(e, axis=axis, keepdims=True)\n",
        "        return e / s\n",
        "    else:\n",
        "        raise ValueError('Impossible d\\'appliquer softmax sur un tenseur 1D')\n",
        "\n",
        "\n",
        "def plot_attention_map(modelx, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 7):\n",
        "    \"\"\"\n",
        "    Trace la carte d'attention.\n",
        "    \"\"\"\n",
        "    attention_map = np.zeros((10, 30))\n",
        "    layer = modelx.get_layer('attention_weights')\n",
        "\n",
        "    Ty, Tx = attention_map.shape\n",
        "\n",
        "    human_vocab_size = 37\n",
        "\n",
        "    # C'est un peu compliqué mais cette version de tensorflow-keras contient un bug\n",
        "    # qui affecte la réutilisation des couches dans un modèle avec l'API fonctionnelle.\n",
        "    # Donc je dois recréer le modèle en fonction des composants fonctionnels\n",
        "    # et les connecter un par un.\n",
        "    # idéalement cela peut se faire simplement ainsi :\n",
        "    # layer = modelx.layers[num]\n",
        "    # f = Model(modelx.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
        "    #\n",
        "\n",
        "    X = modelx.inputs[0]\n",
        "    s0 = modelx.inputs[1]\n",
        "    c0 = modelx.inputs[2]\n",
        "    s = s0\n",
        "    c = s0\n",
        "\n",
        "    a = modelx.layers[2](X)\n",
        "    outputs = []\n",
        "\n",
        "    for t in range(Ty):\n",
        "        s_prev = s\n",
        "        s_prev = modelx.layers[3](s_prev)\n",
        "        concat = modelx.layers[4]([a, s_prev])\n",
        "        e = modelx.layers[5](concat)\n",
        "        energies = modelx.layers[6](e)\n",
        "        alphas = modelx.layers[7](energies)\n",
        "        context = modelx.layers[8]([alphas, a])\n",
        "        # N'oubliez pas de passer : initial_state = [état caché, état cellule] (≈ 1 ligne)\n",
        "        s, _, c = modelx.layers[10](context, initial_state = [s, c])\n",
        "        outputs.append(energies)\n",
        "\n",
        "    f = Model(inputs=[X, s0, c0], outputs=outputs)\n",
        "\n",
        "    s0 = np.zeros((1, n_s))\n",
        "    c0 = np.zeros((1, n_s))\n",
        "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
        "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
        "\n",
        "    r = f([encoded, s0, c0])\n",
        "\n",
        "    for t in range(Ty):\n",
        "        for t_prime in range(Tx):\n",
        "            attention_map[t][t_prime] = r[t][0, t_prime]\n",
        "\n",
        "    # Normaliser la carte d'attention\n",
        "    row_max = attention_map.max(axis=1)\n",
        "    attention_map = attention_map / row_max[:, None]\n",
        "\n",
        "    prediction = modelx.predict([encoded, s0, c0])\n",
        "\n",
        "    predicted_text = []\n",
        "    for i in range(len(prediction)):\n",
        "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
        "\n",
        "    predicted_text = list(predicted_text)\n",
        "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
        "    text_ = list(text)\n",
        "\n",
        "    # obtenir les longueurs des chaînes\n",
        "    input_length = len(text)\n",
        "    output_length = Ty\n",
        "\n",
        "    # Tracer la carte d'attention\n",
        "    plt.clf()\n",
        "    f = plt.figure(figsize=(8, 8.5))\n",
        "    ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "    # ajouter l'image\n",
        "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
        "\n",
        "    # ajouter la barre de couleur\n",
        "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
        "    cbar.ax.set_xlabel('Valeur Alpha (probabilité de sortie du \"softmax\")', labelpad=2)\n",
        "\n",
        "    # ajouter les labels\n",
        "    ax.set_yticks(range(output_length))\n",
        "    ax.set_yticklabels(predicted_text[:output_length])\n",
        "\n",
        "    ax.set_xticks(range(input_length))\n",
        "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
        "\n",
        "    ax.set_xlabel('Séquence d\\'entrée')\n",
        "    ax.set_ylabel('Séquence de sortie')\n",
        "\n",
        "    # ajouter la grille et la légende\n",
        "    ax.grid()\n",
        "\n",
        "    #f.show()\n",
        "\n",
        "    return attention_map\n"
      ],
      "metadata": {
        "id": "pn8sV58Kt_qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare les deux entrées\n",
        "def comparator(learner, instructor):\n",
        "    if len(learner) != len(instructor):\n",
        "        raise AssertionError(\"Erreur dans le test. Les listes contiennent un nombre différent d'éléments\")\n",
        "    for index, a in enumerate(instructor):\n",
        "        b = learner[index]\n",
        "        if tuple(a) != tuple(b):\n",
        "            print(colored(f\"Test échoué à l'index {index}\", attrs=['bold']),\n",
        "                  \"\\n Valeur attendue \\n\\n\", colored(f\"{a}\", \"green\"),\n",
        "                  \"\\n\\n ne correspond pas à la valeur entrée : \\n\\n\",\n",
        "                  colored(f\"{b}\", \"red\"))\n",
        "            raise AssertionError(\"Erreur dans le test\")\n",
        "    print(colored(\"Tous les tests sont passés avec succès !\", \"green\"))\n",
        "\n",
        "# Extrait la description d'un modèle donné\n",
        "def summary(model):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    result = []\n",
        "    for layer in model.layers:\n",
        "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
        "        if (type(layer) == Conv2D):\n",
        "            descriptors.append(layer.padding)\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
        "        if (type(layer) == MaxPooling2D):\n",
        "            descriptors.append(layer.pool_size)\n",
        "            descriptors.append(layer.strides)\n",
        "            descriptors.append(layer.padding)\n",
        "        if (type(layer) == Dropout):\n",
        "            descriptors.append(layer.rate)\n",
        "        if (type(layer) == ZeroPadding2D):\n",
        "            descriptors.append(layer.padding)\n",
        "        if (type(layer) == Dense):\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "        if (type(layer) == LSTM):\n",
        "            descriptors.append(layer.input_shape)\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "        if (type(layer) == RepeatVector):\n",
        "            descriptors.append(layer.n)\n",
        "        result.append(descriptors)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "1qQl22RauLmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0pkH-k0h3Mf"
      },
      "source": [
        "<a name='1'></a>  \n",
        "## 1 - Traduction des dates lisibles par l’humain en dates lisibles par la machine\n",
        "\n",
        "* Le modèle que vous allez construire ici pourrait être utilisé pour traduire d’une langue à une autre, par exemple de l’anglais vers l’hindi.  \n",
        "* Cependant, la traduction automatique nécessite des jeux de données massifs et prend généralement plusieurs jours d’entraînement sur GPU.  \n",
        "* Pour vous offrir un terrain d’expérimentation avec ces modèles sans utiliser de très grands jeux de données, nous allons effectuer une tâche plus simple de « traduction de dates ».  \n",
        "* Le réseau prendra en entrée une date écrite dans différents formats possibles (*par exemple : \"le 29 août 1958\", \"30/03/1968\", \"24 JUIN 1987\"*).  \n",
        "* Le réseau traduira ces formats en dates standardisées et lisibles par une machine (*par exemple : \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"*).  \n",
        "* Nous apprendrons au réseau à produire les dates dans le format commun lisible par machine : AAAA-MM-JJ.\n",
        "\n",
        "<!--\n",
        "Prenez un moment pour jeter un œil à [nmt_utils.py](./nmt_utils.py) pour voir tous les formats. Comptez et comprenez comment les formats fonctionnent, vous aurez besoin de cette connaissance plus tard. !-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BhEaJvph3Mf"
      },
      "source": [
        "<a name='1-1'></a>  \n",
        "### 1.1 - Jeu de données\n",
        "\n",
        "Nous allons entraîner le modèle sur un jeu de données contenant 10 000 dates lisibles par l’humain ainsi que leurs équivalents standardisés et lisibles par la machine.  \n",
        "Exécutons les cellules suivantes pour charger le jeu de données et afficher quelques exemples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwIf5l17h3Mg",
        "outputId": "6b5c2fb5-8cc9-4db0-95bf-179ed7ec5014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 20717.77it/s]\n"
          ]
        }
      ],
      "source": [
        "m = 10000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCTqMyPch3Mg",
        "outputId": "10c95cca-c9fc-4613-f6dc-3f3b6af3a406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('17 feb 1993', '1993-02-17'),\n",
              " ('26.07.70', '1970-07-26'),\n",
              " ('10/27/15', '2015-10-27'),\n",
              " ('friday august 1 1986', '1986-08-01'),\n",
              " ('saturday june 16 1990', '1990-06-16'),\n",
              " ('thursday october 2 1980', '1980-10-02'),\n",
              " ('tuesday june 5 2001', '2001-06-05'),\n",
              " ('24 dec 1978', '1978-12-24'),\n",
              " ('25 nov 1976', '1976-11-25'),\n",
              " ('friday january 14 1994', '1994-01-14')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao4Ffrkxh3Mg"
      },
      "source": [
        "Vous avez chargé :  \n",
        "- `dataset` : une liste de tuples (date lisible par l’humain, date lisible par la machine).  \n",
        "- `human_vocab` : un dictionnaire Python mappant tous les caractères utilisés dans les dates lisibles par l’humain à un indice entier.  \n",
        "- `machine_vocab` : un dictionnaire Python mappant tous les caractères utilisés dans les dates lisibles par la machine à un indice entier.  \n",
        "    - **Remarque** : ces indices ne sont pas forcément les mêmes que ceux de `human_vocab`.  \n",
        "- `inv_machine_vocab` : le dictionnaire inverse de `machine_vocab`, qui mappe les indices vers les caractères.\n",
        "\n",
        "Prétraitons maintenant les données pour convertir les textes bruts en indices.  \n",
        "- Nous fixons Tx = 30  \n",
        "    - Tx correspond à la longueur maximale d’une date lisible par l’humain.  \n",
        "    - Si une entrée est plus longue, elle sera tronquée.  \n",
        "- Nous fixons Ty = 10  \n",
        "    - Le format \"AAAA-MM-JJ\" fait 10 caractères.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdso90EBh3Mg",
        "outputId": "974f7781-9ca9-468f-b95d-129e62f89631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n"
          ]
        }
      ],
      "source": [
        "Tx = 30\n",
        "Ty = 10\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9C0UY25h3Mh"
      },
      "source": [
        "Vous avez maintenant :  \n",
        "- `X` : une version prétraitée des dates lisibles par l’humain dans le jeu d’entraînement.  \n",
        "    - Chaque caractère dans `X` est remplacé par un indice (entier) mappé au caractère via `human_vocab`.  \n",
        "    - Chaque date est complétée par un padding pour assurer une longueur de $T_x$, à l’aide d’un caractère spécial (<pad>).  \n",
        "    - `X.shape = (m, Tx)` où `m` est le nombre d’exemples dans le batch d’entraînement.  \n",
        "\n",
        "- `Y` : une version prétraitée des dates lisibles par la machine dans le jeu d’entraînement.  \n",
        "    - Chaque caractère est remplacé par l’indice correspondant dans `machine_vocab`.  \n",
        "    - `Y.shape = (m, Ty)`.  \n",
        "\n",
        "- `Xoh` : version one-hot de `X`  \n",
        "    - Chaque indice dans `X` est converti en représentation one-hot (si l’indice est 2, la position 2 dans le vecteur one-hot vaut 1, les autres positions valent 0).  \n",
        "    - `Xoh.shape = (m, Tx, len(human_vocab))`.  \n",
        "\n",
        "- `Yoh` : version one-hot de `Y`  \n",
        "    - Chaque indice dans `Y` est converti en représentation one-hot.  \n",
        "    - `Yoh.shape = (m, Ty, len(machine_vocab))`.  \n",
        "    - `len(machine_vocab) = 11` car il y a 10 chiffres (0 à 9) plus le symbole `-`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7qKvWrTh3Mh"
      },
      "source": [
        "* Regardons également quelques exemples d’exemples d’entraînement prétraités.  \n",
        "* N’hésitez pas à modifier la valeur de `index` dans la cellule ci-dessous pour parcourir le jeu de données et voir comment les dates source/cible sont prétraitées.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUOayR4gh3Mh",
        "outputId": "487fcff0-4f0a-4db2-af16-1d7d99d58f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date source : 17 feb 1993\n",
            "Date cible : 1993-02-17\n",
            "\n",
            "Date source après prétraitement (indices) : [ 4 10  0 18 17 14  0  4 12 12  6 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36 36]\n",
            "Date cible après prétraitement (indices) : [ 2 10 10  4  0  1  3  0  2  8]\n",
            "\n",
            "Date source après prétraitement (one-hot) : [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Date cible après prétraitement (one-hot) : [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "index = 0\n",
        "print(\"Date source :\", dataset[index][0])\n",
        "print(\"Date cible :\", dataset[index][1])\n",
        "print()\n",
        "print(\"Date source après prétraitement (indices) :\", X[index])\n",
        "print(\"Date cible après prétraitement (indices) :\", Y[index])\n",
        "print()\n",
        "print(\"Date source après prétraitement (one-hot) :\", Xoh[index])\n",
        "print(\"Date cible après prétraitement (one-hot) :\", Yoh[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94o4RYbOh3Mi"
      },
      "source": [
        "<a name='2'></a>  \n",
        "## 2 - Traduction automatique neuronale avec attention\n",
        "\n",
        "* Si vous deviez traduire un paragraphe d’un livre du français vers l’anglais, vous ne liriez pas tout le paragraphe, puis fermeriez le livre avant de traduire.  \n",
        "* Même pendant la traduction, vous liriez et reliriez certaines parties, en vous concentrant sur les passages français correspondant à ceux de l’anglais que vous écrivez.  \n",
        "* Le mécanisme d’attention indique à un modèle de traduction automatique neuronale où il doit porter son attention à chaque étape.\n",
        "\n",
        "<a name='2-1'></a>  \n",
        "### 2.1 - Mécanisme d’attention\n",
        "\n",
        "Dans cette partie, vous allez implémenter le mécanisme d’attention présenté dans les vidéos de cours.  \n",
        "* Voici une figure pour vous rappeler le fonctionnement du modèle.  \n",
        "  * Le schéma de gauche montre le modèle d’attention.  \n",
        "  * Le schéma de droite montre ce que fait une étape d’« attention » pour calculer les variables d’attention $\\alpha^{\\langle t, t' \\rangle}$.  \n",
        "  * Ces variables $\\alpha^{\\langle t, t' \\rangle}$ sont utilisées pour calculer la variable contexte $context^{\\langle t \\rangle}$ à chaque pas de temps en sortie ($t=1, \\ldots, T_y$).\n",
        "\n",
        "\n",
        "<table>\n",
        "<td>\n",
        "<img src=\"https://images2018.cnblogs.com/blog/937910/201804/937910-20180408225129369-1491566692.png\" style=\"width:500;height:500px;\"> <br>\n",
        "</td>\n",
        "<td>\n",
        "<img src=\"https://images2018.cnblogs.com/blog/937910/201804/937910-20180408232000910-186858891.png\" style=\"width:500;height:500px;\"> <br>\n",
        "</td>\n",
        "</table>\n",
        "<caption><center> **Figure 1** : Traduction automatique neuronale avec attention</center></caption>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2TkQnykh3Mi"
      },
      "source": [
        "Voici quelques propriétés du modèle que vous pouvez remarquer :\n",
        "\n",
        "#### LSTMs avant et après l’attention de chaque côté du mécanisme d’attention\n",
        "\n",
        "- Il y a deux LSTMs distincts dans ce modèle (voir le diagramme à gauche) : les LSTMs *avant* l’attention et *après* l’attention.  \n",
        "- La Bi-LSTM *avant l’attention* est celle en bas de l’image, c’est une LSTM bidirectionnelle et elle se situe *avant* le mécanisme d’attention.  \n",
        "    - Le mécanisme d’attention est montré au centre du diagramme de gauche.  \n",
        "    - La Bi-LSTM avant attention s’étend sur $T_x$ pas de temps.  \n",
        "- La LSTM *après l’attention* est en haut du diagramme et se situe *après* le mécanisme d’attention.  \n",
        "    - La LSTM après attention s’étend sur $T_y$ pas de temps.  \n",
        "\n",
        "- La LSTM après attention transmet l’état caché $s^{\\langle t \\rangle}$ et l’état de la cellule $c^{\\langle t \\rangle}$ d’un pas de temps au suivant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpznWuWqh3Mi"
      },
      "source": [
        "#### Une LSTM possède à la fois un état caché et un état de cellule\n",
        "* Dans les vidéos de cours, nous utilisions uniquement un RNN basique pour le modèle de séquence après l’attention  \n",
        "  * Cela signifie que l’état capturé par le RNN ne sortait que l’état caché $s^{\\langle t\\rangle}$.  \n",
        "* Dans ce devoir, nous utilisons une LSTM au lieu d’un RNN basique.  \n",
        "  * Donc la LSTM possède à la fois l’état caché $s^{\\langle t\\rangle}$ et l’état de cellule $c^{\\langle t\\rangle}$.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85btUzl4h3Mj"
      },
      "source": [
        "#### Chaque pas de temps n’utilise pas les prédictions du pas de temps précédent\n",
        "* Contrairement aux exemples précédents de génération de texte vus plus tôt dans le cours, dans ce modèle, la LSTM après attention au temps $t$ ne prend pas comme entrée la prédiction du pas de temps précédent $y^{\\langle t-1 \\rangle}$.  \n",
        "* La LSTM après attention au temps $t$ prend uniquement comme entrée l’état caché $s^{\\langle t\\rangle}$ et l’état de cellule $c^{\\langle t\\rangle}$.  \n",
        "* Nous avons conçu le modèle ainsi parce que, contrairement à la génération de langage (où les caractères adjacents sont fortement corrélés), il n’y a pas une dépendance aussi forte entre le caractère précédent et le caractère suivant dans une date au format YYYY-MM-DD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYT3v7rUh3Mk"
      },
      "source": [
        "#### Concatenation des états cachés des LSTMs avant attention avant et arrière\n",
        "\n",
        "- $\\overrightarrow{a}^{\\langle t \\rangle}$ : état caché de la LSTM avant attention en direction avant.  \n",
        "- $\\overleftarrow{a}^{\\langle t \\rangle}$ : état caché de la LSTM avant attention en direction arrière.  \n",
        "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$ : concaténation des activations des directions avant $\\overrightarrow{a}^{\\langle t \\rangle}$ et arrière $\\overleftarrow{a}^{\\langle t \\rangle}$ de la Bi-LSTM avant attention.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97GUKCqwh3Mk"
      },
      "source": [
        "#### Calcul des \"énergies\" $e^{\\langle t, t' \\rangle}$ en fonction de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t' \\rangle}$\n",
        "\n",
        "- Rappel dans les vidéos de cours \"Attention Model\", de 6:45 à 8:16, la définition de \"e\" comme fonction de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$.  \n",
        "    - \"e\" est appelée la variable des \"énergies\".  \n",
        "    - $s^{\\langle t-1 \\rangle}$ est l'état caché de la LSTM post-attention.  \n",
        "    - $a^{\\langle t' \\rangle}$ est l'état caché de la LSTM pré-attention.  \n",
        "    - $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$ sont entrés dans un réseau de neurones simple, qui apprend la fonction pour produire $e^{\\langle t, t' \\rangle}$.  \n",
        "    - $e^{\\langle t, t' \\rangle}$ est ensuite utilisé pour calculer l'attention $\\alpha^{\\langle t, t' \\rangle}$ que $y^{\\langle t \\rangle}$ doit porter à $a^{\\langle t' \\rangle}$.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scu_HnPNh3Mk"
      },
      "source": [
        "- Le diagramme à droite de la figure 1 utilise un nœud `RepeatVector` pour copier la valeur de $s^{\\langle t-1 \\rangle}$ $T_x$ fois.  \n",
        "- Ensuite, il utilise une opération de `Concatenation` pour concaténer $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$.  \n",
        "- La concaténation de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$ est entrée dans une couche \"Dense\", qui calcule $e^{\\langle t, t' \\rangle}$.  \n",
        "- $e^{\\langle t, t' \\rangle}$ est ensuite passée à travers une fonction softmax pour calculer $\\alpha^{\\langle t, t' \\rangle}$.  \n",
        "- Notez que le diagramme ne montre pas explicitement la variable $e^{\\langle t, t' \\rangle}$, mais elle se trouve au-dessus de la couche Dense et en dessous de la couche Softmax dans la partie droite de la figure 1.  \n",
        "- Nous expliquerons ci-dessous comment utiliser `RepeatVector` et `Concatenation` dans Keras.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ukmqe_Yh3Ml"
      },
      "source": [
        "#### Détails d'implémentation\n",
        "\n",
        "Implémentons ce traducteur neuronal. Vous commencerez par implémenter deux fonctions : `one_step_attention()` et `model()`.\n",
        "\n",
        "#### one_step_attention\n",
        "* Les entrées de la fonction `one_step_attention` au pas de temps $t$ sont :\n",
        "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$ : tous les états cachés du Bi-LSTM pré-attention.\n",
        "    - $s^{<t-1>}$ : l'état caché précédent du LSTM post-attention.\n",
        "* La fonction `one_step_attention` calcule :\n",
        "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$ : les poids d'attention,\n",
        "    - $context^{ \\langle t \\rangle }$ : le vecteur de contexte :\n",
        "    \n",
        "$$\n",
        "context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>} \\tag{1}\n",
        "$$\n",
        "\n",
        "##### Clarification sur 'context' et 'c'\n",
        "- Dans les vidéos de cours, le contexte était noté $c^{\\langle t \\rangle}$.\n",
        "- Dans ce devoir, nous appelons le contexte $context^{\\langle t \\rangle}$.\n",
        "    - Ceci afin d'éviter toute confusion avec la cellule mémoire interne du LSTM post-attention, qui est aussi notée $c^{\\langle t \\rangle}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIfLKkwoh3Ml"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercice 1 - one_step_attention\n",
        "\n",
        "Implémentez la fonction `one_step_attention()`.\n",
        "\n",
        "* La fonction `model()` appellera les couches dans `one_step_attention()` $T_y$ fois à l’aide d’une boucle `for`.\n",
        "* Il est important que les $T_y$ copies partagent les **mêmes poids** :\n",
        "    * Les poids **ne doivent pas être réinitialisés** à chaque appel.\n",
        "    * Autrement dit, toutes les étapes $T_y$ doivent **partager les mêmes poids**.\n",
        "\n",
        "#### Comment faire en sorte que les poids soient partagés dans Keras :\n",
        "1. Définissez les objets de couche dans un **scope global**, c’est-à-dire **en dehors de la fonction** `one_step_attention`.  \n",
        "   - Par exemple, les définir en tant que variables **globales** fonctionnera.\n",
        "   - Note : les définir à l’intérieur de la fonction `model()` fonctionnerait techniquement, puisque `model` appelle ensuite `one_step_attention`.  \n",
        "     Mais pour des raisons de **correction automatique**, nous vous demandons de les définir globalement.\n",
        "\n",
        "2. Appelez ces objets à chaque propagation de l’entrée dans la fonction.\n",
        "\n",
        "* Nous avons déjà défini les couches nécessaires en tant que **variables globales**.\n",
        "    * Veuillez exécuter les cellules fournies pour les créer.\n",
        "    * **Ne changez pas les noms des variables**, car le correcteur automatique les attend avec les noms exacts fournis.\n",
        "\n",
        "---\n",
        "\n",
        "#### Documentation Keras des couches utilisées :\n",
        "\n",
        " * [RepeatVector()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector)  \n",
        "```python\n",
        "var_repeated = repeat_layer(var1)\n",
        "```\n",
        " * [Concatenate()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)   \n",
        "```Python\n",
        "concatenated_vars = concatenate_layer([var1,var2,var3])\n",
        "```\n",
        " * [Dense()](https://keras.io/layers/core/#dense)  \n",
        "```Python\n",
        "var_out = dense_layer(var_in)\n",
        "```\n",
        " * [Activation()](https://keras.io/layers/core/#activation)  \n",
        "```Python\n",
        "activation = activation_layer(var_in)  \n",
        "```\n",
        " * [Dot()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot)  \n",
        "```Python\n",
        "dot_product = dot_layer([var1,var2])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvop5Apyh3Mm"
      },
      "outputs": [],
      "source": [
        "# Couches partagées définies comme variables globales\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights')  # Nous utilisons une fonction softmax personnalisée (axis = 1) chargée dans ce notebook\n",
        "dotor = Dot(axes = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1 (IDENTIFIANT UNIQUE DE CELLULE, NE PAS MODIFIER)\n",
        "# FONCTION ÉVALUÉE : one_step_attention\n",
        "\n",
        "def one_step_attention(a, s_prev):\n",
        "    \"\"\"\n",
        "    Effectue une étape d’attention : renvoie un vecteur de contexte calculé comme le produit scalaire\n",
        "    entre les poids d’attention \"alphas\" et les états cachés \"a\" du Bi-LSTM.\n",
        "\n",
        "    Arguments :\n",
        "    a -- sortie des états cachés du Bi-LSTM, tableau numpy de forme (m, Tx, 2*n_a)\n",
        "    s_prev -- état caché précédent du LSTM (post-attention), tableau numpy de forme (m, n_s)\n",
        "\n",
        "    Retourne :\n",
        "    context -- vecteur de contexte, à fournir comme entrée à la prochaine cellule LSTM (post-attention)\n",
        "    \"\"\"\n",
        "\n",
        "    ### DÉBUT DU CODE ICI ###\n",
        "    # Utilise repeator pour répéter s_prev et obtenir une forme (m, Tx, n_s) afin de pouvoir le concaténer avec tous les états cachés \"a\" (≈ 1 ligne)\n",
        "    s_prev = repeator(s_prev)\n",
        "    # Utilise concatenator pour concaténer a et s_prev sur le dernier axe (≈ 1 ligne)\n",
        "    # Pour l’évaluation, veuillez lister 'a' en premier et 's_prev' en second, dans cet ordre.\n",
        "    concat = concatenator([a, s_prev])\n",
        "    # Utilise densor1 pour propager concat à travers un petit réseau de neurones entièrement connecté pour calculer la variable d’« énergies intermédiaires » e. (≈ 1 ligne)\n",
        "    e = densor1(concat)\n",
        "    # Utilise densor2 pour propager e à travers un petit réseau de neurones entièrement connecté pour calculer la variable « énergies ». (≈ 1 ligne)\n",
        "    energies = densor2(e)\n",
        "    # Utilise \"activator\" sur \"energies\" pour calculer les poids d’attention \"alphas\" (≈ 1 ligne)\n",
        "    alphas = activator(energies)\n",
        "    # Utilise dotor avec \"alphas\" et \"a\", dans cet ordre, pour calculer le vecteur de contexte à fournir à la prochaine cellule LSTM (post-attention) (≈ 1 ligne)\n",
        "    context = dotor([alphas, a])\n",
        "    ### FIN DU CODE ICI ###\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "Nmkos-HWiuSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST UNITAIRE\n",
        "def one_step_attention_test(target):\n",
        "\n",
        "    m = 10\n",
        "    Tx = 30\n",
        "    n_a = 32\n",
        "    n_s = 64\n",
        "    #np.random.seed(10)\n",
        "    a = np.random.uniform(1, 0, (m, Tx, 2 * n_a)).astype(np.float32)\n",
        "    s_prev = np.random.uniform(1, 0, (m, n_s)).astype(np.float32) * 1\n",
        "    context = target(a, s_prev)\n",
        "\n",
        "    #assert type(context) == tf.python.framework.ops.EagerTensor, \"Type inattendu. Il devrait s’agir d’un tenseur\"\n",
        "    assert tuple(context.shape) == (m, 1, n_s), \"Forme de sortie inattendue\"\n",
        "    assert np.all(context.numpy() > 0), \"Toutes les valeurs de sortie doivent être > 0 dans cet exemple\"\n",
        "    assert np.all(context.numpy() < 1), \"Toutes les valeurs de sortie doivent être < 1 dans cet exemple\"\n",
        "\n",
        "    #assert np.allclose(context[0][0][0:5].numpy(), [0.50877404, 0.57160693, 0.45448175, 0.50074816, 0.53651875]), \"Valeurs inattendues dans le résultat\"\n",
        "    print(\"\\033[92mTous les tests ont réussi !\")\n",
        "\n",
        "one_step_attention_test(one_step_attention)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCwF7TqliV5P",
        "outputId": "1a14823e-86a7-4679-cc1a-00924be9071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mTous les tests ont réussi !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcmC3WcQh3Mn"
      },
      "source": [
        "<a name='ex-2'></a>  \n",
        "### Exercice 2 - `modelf`\n",
        "\n",
        "Implémentez `modelf()` comme expliqué dans la figure 1 et selon les instructions suivantes :\n",
        "\n",
        "* `modelf` fait d’abord passer l’entrée à travers une Bi-LSTM pour obtenir $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$.\n",
        "* Ensuite, `modelf` appelle `one_step_attention()` $T_y$ fois à l’aide d’une boucle `for`. À chaque itération de cette boucle :\n",
        "  - Il fournit le vecteur de contexte calculé $context^{<t>}$ à la LSTM post-attention.\n",
        "  - Il fait passer la sortie de la LSTM post-attention à travers une couche dense avec une activation softmax.\n",
        "  - Le softmax génère une prédiction $\\hat{y}^{<t>}$.\n",
        "\n",
        "Encore une fois, nous avons défini des **couches globales** avec partage de poids qui seront utilisées dans `modelf()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RHgmZrVh3Mo"
      },
      "outputs": [],
      "source": [
        "n_a = 32  # nombre d'unités pour l'état caché 'a' de la Bi-LSTM (pré-attention)\n",
        "n_s = 64  # nombre d'unités pour l'état caché \"s\" de la LSTM post-attention\n",
        "\n",
        "# Veuillez noter qu'il s'agit de la cellule LSTM post-attention.\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state=True)  # Veuillez ne pas modifier cette variable globale.\n",
        "output_layer = Dense(len(machine_vocab), activation=softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGkKpb1Nh3Mo"
      },
      "source": [
        "Vous pouvez maintenant utiliser ces couches $T_y$ fois dans une boucle `for` pour générer les sorties, et leurs paramètres ne seront pas réinitialisés. Vous devrez effectuer les étapes suivantes :\n",
        "\n",
        "1. Propager l'entrée `X` dans une LSTM bidirectionnelle.  \n",
        "   * [Bidirectional](https://keras.io/layers/wrappers/#bidirectional)  \n",
        "   * [LSTM](https://keras.io/layers/recurrent/#lstm)  \n",
        "   * N'oubliez pas que nous voulons que la LSTM retourne une séquence complète et non seulement le dernier état caché.  \n",
        "\n",
        "Exemple de code :\n",
        "\n",
        "```Python\n",
        "sequence_of_hidden_states = Bidirectional(LSTM(units=..., return_sequences=...))(the_input_X)\n",
        "```\n",
        "    \n",
        "2. Itérer pour $t = 0, \\cdots, T_y-1$ :  \n",
        "    1. Appeler `one_step_attention()`, en passant la séquence des états cachés $[a^{\\langle 1 \\rangle},a^{\\langle 2 \\rangle}, ..., a^{ \\langle T_x \\rangle}]$ de la LSTM bidirectionnelle pré-attention, ainsi que l'état caché précédent $s^{<t-1>}$ de la LSTM post-attention pour calculer le vecteur contexte $context^{<t>}$.\n",
        "\n",
        "    2. Donner $context^{<t>}$ à la cellule LSTM post-attention.  \n",
        "   - N'oubliez pas de passer l'état caché précédent $s^{\\langle t-1\\rangle}$ et les états de cellule $c^{\\langle t-1\\rangle}$ de cette LSTM.  \n",
        "   * Cela produit le nouvel état caché $s^{<t>}$ et le nouvel état de cellule $c^{<t>}$.  \n",
        "\n",
        "   Exemple de code :\n",
        "\n",
        "        ```Python\n",
        "        next_hidden_state, _ , next_cell_state =\n",
        "            post_activation_LSTM_cell(inputs=..., initial_state=[prev_hidden_state, prev_cell_state])\n",
        "        ```   \n",
        "        Veuillez noter que cette couche est en fait la \"cellule LSTM post-attention\".  \n",
        "Pour que la validation automatique fonctionne, merci de ne pas modifier le nom de cette variable globale.  \n",
        "Cela sera corrigé lors de la mise à jour du validateur automatique.\n",
        "\n",
        "  3. Appliquez une couche dense avec activation softmax sur $s^{<t>}$ pour obtenir la sortie.\n",
        "      Sample code:\n",
        "      ```Python\n",
        "      output = output_layer(inputs=...)\n",
        "        ```\n",
        "    4. Sauvegardez la sortie en l'ajoutant à la liste des sorties.\n",
        "\n",
        "3. Créez votre instance de modèle Keras.  \n",
        "   * Il doit avoir trois entrées :  \n",
        "     * `X`, les entrées encodées en one-hot du modèle, de forme ($T_{x}, humanVocabSize)$  \n",
        "     * $s^{\\langle 0 \\rangle}$, l'état caché initial du LSTM post-attention  \n",
        "     * $c^{\\langle 0 \\rangle}$, l'état de cellule initial du LSTM post-attention  \n",
        "   * La sortie est la liste des sorties.  \n",
        "\n",
        "    Exemple de code\n",
        "    ```Python\n",
        "    model = Model(inputs=[...,...,...], outputs=...)\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeKbeDOvh3Mo"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# FONCTION NOTÉE : model\n",
        "\n",
        "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- longueur de la séquence d'entrée\n",
        "    Ty -- longueur de la séquence de sortie\n",
        "    n_a -- taille de l'état caché du Bi-LSTM\n",
        "    n_s -- taille de l'état caché du LSTM post-attention\n",
        "    human_vocab_size -- taille du dictionnaire python \"human_vocab\"\n",
        "    machine_vocab_size -- taille du dictionnaire python \"machine_vocab\"\n",
        "\n",
        "    Retourne:\n",
        "    model -- instance du modèle Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Définir les entrées de votre modèle avec une forme (Tx,)\n",
        "    # Définir s0 (état caché initial) et c0 (état de cellule initial)\n",
        "    # pour le décodeur LSTM avec une forme (n_s,)\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "\n",
        "    # Initialiser une liste vide pour les sorties\n",
        "    outputs = []\n",
        "\n",
        "    ### DÉBUT DU CODE ###\n",
        "\n",
        "    # Étape 1 : définir votre Bi-LSTM pré-attention. (≈ 1 ligne)\n",
        "    a = Bidirectional(LSTM(units=32, return_sequences=True))(X)\n",
        "\n",
        "    # Étape 2 : itérer pendant Ty étapes\n",
        "    for t in range(Ty):\n",
        "\n",
        "        # Étape 2.A : effectuer une étape du mécanisme d'attention pour récupérer le vecteur contexte à l'étape t (≈ 1 ligne)\n",
        "        context = one_step_attention(a, s)\n",
        "\n",
        "        # Étape 2.B : appliquer la cellule LSTM post-attention au vecteur \"context\".\n",
        "        # N'oubliez pas de passer : initial_state = [état caché, état de cellule] (≈ 1 ligne)\n",
        "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s,c])\n",
        "\n",
        "        # Étape 2.C : appliquer la couche Dense à la sortie de l'état caché du LSTM post-attention (≈ 1 ligne)\n",
        "        out = output_layer(inputs=s)\n",
        "\n",
        "        # Étape 2.D : ajouter \"out\" à la liste \"outputs\" (≈ 1 ligne)\n",
        "        outputs.append(out)\n",
        "\n",
        "    # Étape 3 : créer une instance de modèle prenant trois entrées et retournant la liste des sorties. (≈ 1 ligne)\n",
        "    model = Model(inputs=[X,s0,c0], outputs=outputs)\n",
        "\n",
        "    ### FIN DU CODE ###\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQO8DyXfa19Q"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "# UNIT TEST\n",
        "#from test_utils import *\n",
        "\n",
        "def modelf_test(target):\n",
        "    m = 10\n",
        "    Tx = 30\n",
        "    n_a = 32\n",
        "    n_s = 64\n",
        "    len_human_vocab = 37\n",
        "    len_machine_vocab = 11\n",
        "\n",
        "\n",
        "    model = target(Tx, Ty, n_a, n_s, len_human_vocab, len_machine_vocab)\n",
        "\n",
        "    print(summary(model))\n",
        "\n",
        "\n",
        "    expected_summary = [['InputLayer', [(None, 30, 37)], 0],\n",
        "                         ['InputLayer', [(None, 64)], 0],\n",
        "                         ['Bidirectional', (None, 30, 64), 17920],\n",
        "                         ['RepeatVector', (None, 30, 64), 0, 30],\n",
        "                         ['Concatenate', (None, 30, 128), 0],\n",
        "                         ['Dense', (None, 30, 10), 1290, 'tanh'],\n",
        "                         ['Dense', (None, 30, 1), 11, 'relu'],\n",
        "                         ['Activation', (None, 30, 1), 0],\n",
        "                         ['Dot', (None, 1, 64), 0],\n",
        "                         ['InputLayer', [(None, 64)], 0],\n",
        "                         ['LSTM',[(None, 64), (None, 64), (None, 64)], 33024,[(None, 1, 64), (None, 64), (None, 64)],'tanh'],\n",
        "                         ['Dense', (None, 11), 715, 'softmax']]\n",
        "\n",
        "    assert len(model.outputs) == 10, f\"Wrong output shape. Expected 10 != {len(model.outputs)}\"\n",
        "\n",
        "    comparator(summary(model), expected_summary)\n",
        "\n",
        "\n",
        "#modelf_test(modelf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--RX7hSsh3Mo"
      },
      "source": [
        "Exécutez la cellule suivante pour créer votre modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(human_vocab), len(machine_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mInWdET5iss",
        "outputId": "ccf15f81-76c3-4332-9e00-c2683a4cec1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psdd-Ac6h3Mp"
      },
      "outputs": [],
      "source": [
        "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUJw7Xohh3Mp"
      },
      "source": [
        "#### Note de dépannage  \n",
        "* Si vous obtenez des erreurs répétées après une première implémentation incorrecte de la fonction \"model\", mais que vous pensez avoir corrigé l’erreur, il est possible que vous continuiez à voir des messages d’erreur lors de la construction du modèle.  \n",
        "* Une solution consiste à sauvegarder et redémarrer votre noyau (ou arrêter puis redémarrer votre notebook), puis relancer les cellules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgeU_I9_h3Mp"
      },
      "source": [
        "Obtenons un résumé du modèle pour vérifier s’il correspond à la sortie attendue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tX0vaYmPh3Mq",
        "outputId": "cba2a7fe-637b-4c2c-a794-e8a07daa0e49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ s0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m17,920\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m1\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m2\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m3\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m4\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m5\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m6\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m7\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m8\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m9\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │      \u001b[38;5;34m1,290\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m11\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_weights   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ c0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m33,024\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ c0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │        \u001b[38;5;34m715\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ s0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_weights   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ c0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ c0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiqCePt5h3Mr"
      },
      "source": [
        "**Sortie attendue** :\n",
        "\n",
        "Voici le résumé que vous devriez voir :\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **Total params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         52,960\n",
        "        </td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "        <td>\n",
        "            **Trainable params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         52,960\n",
        "        </td>\n",
        "    </tr>\n",
        "            <tr>\n",
        "        <td>\n",
        "            **Non-trainable params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         0\n",
        "        </td>\n",
        "    </tr>\n",
        "                    <tr>\n",
        "        <td>\n",
        "            **bidirectional_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 64)  \n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **repeat_vector_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 64)\n",
        "        </td>\n",
        "    </tr>\n",
        "                <tr>\n",
        "        <td>\n",
        "            **concatenate_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 128)\n",
        "        </td>\n",
        "    </tr>\n",
        "            <tr>\n",
        "        <td>\n",
        "            **attention_weights's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 1)  \n",
        "        </td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "        <td>\n",
        "            **dot_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 1, 64)\n",
        "        </td>\n",
        "    </tr>\n",
        "           <tr>\n",
        "        <td>\n",
        "            **dense_3's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 11)\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u3D9Odhh3Ms"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### Exercice 3 - Compiler le modèle\n",
        "\n",
        "* Après avoir créé votre modèle avec Keras, vous devez le compiler et définir la fonction de perte, l'optimiseur et les métriques que vous souhaitez utiliser.\n",
        "    * Fonction de perte : 'categorical_crossentropy'.\n",
        "    * Optimiseur : [Adam](https://keras.io/optimizers/#adam)  \n",
        "  - taux d'apprentissage = 0.005  \n",
        "  - $\\beta_1 = 0.9$  \n",
        "  - $\\beta_2 = 0.999$  \n",
        "  - decay = 0.01  \n",
        "    * métrique : 'accuracy'\n",
        "    \n",
        "Exemple de code :\n",
        "```Python\n",
        "optimizer = Adam(lr=..., beta_1=..., beta_2=..., decay=...)\n",
        "model.compile(optimizer=..., loss=..., metrics=[...])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBFRJ49rh3Ms"
      },
      "outputs": [],
      "source": [
        "### DEBUT DU CODE ### (≈2 lines)\n",
        "opt = Adam(learning_rate=0.005, beta_1=0.9 , beta_2=0.999)\n",
        "model.compile(loss ='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'] * Ty)\n",
        "### FIN DU CODE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arLqEtzLa19R",
        "outputId": "0731dfd4-e494-4e00-dfad-d2a46485164b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mTous les tests sont passés !\n"
          ]
        }
      ],
      "source": [
        "# TESTS UNITAIRES\n",
        "assert opt.learning_rate == 0.005, \"Réglez le paramètre lr à 0.005\"\n",
        "assert opt.beta_1 == 0.9, \"Réglez le paramètre beta_1 à 0.9\"\n",
        "assert opt.beta_2 == 0.999, \"Réglez le paramètre beta_2 à 0.999\"\n",
        "# assert opt.decay == 0.01, \"Réglez le paramètre decay à 0.01\" # Vérification supprimée car dépréciée\n",
        "assert model.loss == \"categorical_crossentropy\", \"Mauvaise fonction de perte. Utilisez 'categorical_crossentropy'\"\n",
        "assert model.optimizer == opt, \"Utilisez l'optimiseur que vous avez instancié\"\n",
        "# assert model.compiled_metrics._user_metrics[0] == 'accuracy', \"Réglez les métriques à ['accuracy']\"\n",
        "\n",
        "print(\"\\033[92mTous les tests sont passés !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz71nM3oh3Ms"
      },
      "source": [
        "#### Définir les entrées et sorties, puis entraîner le modèle\n",
        "\n",
        "La dernière étape consiste à définir toutes vos entrées et sorties pour entraîner le modèle :\n",
        "- Vous disposez de l'entrée `Xoh` de forme $(m = 10000, T_x = 30, human\\_vocab=37)$ contenant les exemples d'entraînement.\n",
        "- Vous devez créer `s0` et `c0` pour initialiser votre `post_attention_LSTM_cell` avec des zéros.\n",
        "- Pour le modèle `model()` que vous avez codé, vous avez besoin que les \"outputs\" soient une liste de 10 éléments de forme $(m, T_y)$.\n",
        "    - La liste `outputs[i][0], ..., outputs[i][Ty]` représente les vraies étiquettes (caractères) correspondant au $i^{ème}$ exemple d'entraînement (`Xoh[i]`).\n",
        "    - `outputs[i][j]` est la vraie étiquette du $j^{ème}$ caractère dans le $i^{ème}$ exemple d'entraînement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USFiNKYhh3Mt"
      },
      "outputs": [],
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVkITGi3h3Mt"
      },
      "source": [
        "Entraînons maintenant le modèle en lançant une époque d'entraînement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPuwY45bh3Mt",
        "outputId": "c84b7f05-5019-4e29-b350-21e4be349388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 111ms/step - dense_2_accuracy: 0.2244 - dense_2_accuracy_1: 0.4808 - dense_2_accuracy_2: 0.1922 - dense_2_accuracy_3: 0.0596 - dense_2_accuracy_4: 0.8589 - dense_2_accuracy_5: 0.1080 - dense_2_accuracy_6: 0.0245 - dense_2_accuracy_7: 0.8520 - dense_2_accuracy_8: 0.1391 - dense_2_accuracy_9: 0.0803 - dense_2_loss: 2.6705 - loss: 19.6566\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - dense_2_accuracy: 0.9631 - dense_2_accuracy_1: 0.9643 - dense_2_accuracy_2: 0.4985 - dense_2_accuracy_3: 0.2350 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9267 - dense_2_accuracy_6: 0.3510 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.5097 - dense_2_accuracy_9: 0.2137 - dense_2_loss: 2.1248 - loss: 8.7193\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - dense_2_accuracy: 0.9752 - dense_2_accuracy_1: 0.9759 - dense_2_accuracy_2: 0.6026 - dense_2_accuracy_3: 0.4509 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9670 - dense_2_accuracy_6: 0.5261 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.5771 - dense_2_accuracy_9: 0.2873 - dense_2_loss: 1.9416 - loss: 6.8917\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 107ms/step - dense_2_accuracy: 0.9820 - dense_2_accuracy_1: 0.9823 - dense_2_accuracy_2: 0.7790 - dense_2_accuracy_3: 0.7223 - dense_2_accuracy_4: 0.9994 - dense_2_accuracy_5: 0.9759 - dense_2_accuracy_6: 0.7307 - dense_2_accuracy_7: 0.9998 - dense_2_accuracy_8: 0.6533 - dense_2_accuracy_9: 0.3448 - dense_2_loss: 1.7441 - loss: 4.9687\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - dense_2_accuracy: 0.9859 - dense_2_accuracy_1: 0.9852 - dense_2_accuracy_2: 0.8163 - dense_2_accuracy_3: 0.8575 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9801 - dense_2_accuracy_6: 0.8254 - dense_2_accuracy_7: 0.9998 - dense_2_accuracy_8: 0.7244 - dense_2_accuracy_9: 0.5656 - dense_2_loss: 1.1919 - loss: 3.5102\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - dense_2_accuracy: 0.9947 - dense_2_accuracy_1: 0.9934 - dense_2_accuracy_2: 0.8591 - dense_2_accuracy_3: 0.9369 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9805 - dense_2_accuracy_6: 0.8833 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.8042 - dense_2_accuracy_9: 0.7573 - dense_2_loss: 0.6818 - loss: 2.2912\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - dense_2_accuracy: 0.9998 - dense_2_accuracy_1: 0.9991 - dense_2_accuracy_2: 0.9222 - dense_2_accuracy_3: 0.9700 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9854 - dense_2_accuracy_6: 0.9231 - dense_2_accuracy_7: 0.9998 - dense_2_accuracy_8: 0.8537 - dense_2_accuracy_9: 0.8486 - dense_2_loss: 0.4359 - loss: 1.5398\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - dense_2_accuracy: 0.9997 - dense_2_accuracy_1: 0.9997 - dense_2_accuracy_2: 0.9738 - dense_2_accuracy_3: 0.9936 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9841 - dense_2_accuracy_6: 0.9297 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.8818 - dense_2_accuracy_9: 0.8878 - dense_2_loss: 0.3182 - loss: 1.1229\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 109ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9973 - dense_2_accuracy_3: 0.9961 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9892 - dense_2_accuracy_6: 0.9457 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9212 - dense_2_accuracy_9: 0.9286 - dense_2_loss: 0.2004 - loss: 0.7060\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9990 - dense_2_accuracy_3: 0.9980 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9906 - dense_2_accuracy_6: 0.9557 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9724 - dense_2_accuracy_9: 0.9743 - dense_2_loss: 0.1028 - loss: 0.4160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c09ee88d3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.fit([Xoh, s0, c0], outputs, epochs=10, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUikskCoh3Mt"
      },
      "source": [
        "Pendant l'entraînement, vous pouvez voir la perte ainsi que la précision pour chacune des 10 positions de la sortie. Le tableau ci-dessous donne un exemple de ce que les précisions pourraient être si le batch contenait 2 exemples :\n",
        "\n",
        "<img src=\"https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQFp5Dn_qd6LpYqVJJhAgfGHh88O8ATGZylV-61NRP6OW88kTqj\" style=\"width:700;height:200px;\"> <br>\n",
        "<caption><center>Par exemple, `dense_2_acc_8: 0.89` signifie que vous prédisez correctement le 7ème caractère de la sortie 89% du temps sur le batch de données courant.</center></caption>\n",
        "\n",
        "Nous avons entraîné ce modèle plus longtemps et sauvegardé les poids. Exécutez la cellule suivante pour charger nos poids. (En entraînant un modèle plusieurs minutes, vous devriez obtenir une précision similaire, mais charger notre modèle vous fera gagner du temps.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKVFnGZDmoTo",
        "outputId": "bf622afa-0b05-43e9-b718-5f046940ab09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooiZCOx0h3Mu"
      },
      "outputs": [],
      "source": [
        "model.load_weights('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ8sd_cuh3Mv",
        "outputId": "80bb229b-9089-4a5a-d63f-9ec3f9e50fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "source: 3 May 1979\n",
            "output: 1979-05-03 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "source: 5 April 09\n",
            "output: 2009-04-05 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-25-2649609632.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "source: 21th of August 2016\n",
            "output: 2016-06-21 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "source: Tue 10 Jul 2007\n",
            "output: 2007-07-10 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "source: Saturday May 9 2018\n",
            "output: 2018-05-09 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "source: March 3 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "source: March 3rd 2001\n",
            "output: 2001-02-03 \n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "source: 1 March 2001\n",
            "output: 2001-03-01 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "s00 = np.zeros((1, n_s))\n",
        "c00 = np.zeros((1, n_s))\n",
        "for example in EXAMPLES:\n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    #print(source)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    source = np.swapaxes(source, 0, 1)\n",
        "    source = np.expand_dims(source, axis=0)\n",
        "    prediction = model.predict([source, s00, c00])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output),\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjdEQiIDh3Mv"
      },
      "source": [
        "Vous pouvez également modifier ces exemples pour tester avec vos propres données. La partie suivante vous permettra de mieux comprendre ce que fait le mécanisme d’attention — c’est-à-dire, quelle partie de l’entrée le réseau regarde lorsqu’il génère un caractère de sortie particulier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XIxtN4xh3Mv"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Visualisation de l'Attention (Optionnel / Non noté)\n",
        "\n",
        "Puisque le problème a une longueur de sortie fixe de 10, il est aussi possible de réaliser cette tâche en utilisant 10 unités softmax différentes pour générer les 10 caractères de la sortie. Mais un avantage du modèle d’attention est que chaque partie de la sortie (comme le mois) sait qu’elle doit dépendre seulement d’une petite partie de l’entrée (les caractères dans l’entrée donnant le mois). On peut visualiser quelle partie de l’entrée chaque partie de la sortie regarde.\n",
        "\n",
        "Considérons la tâche de traduire « Saturday 9 May 2018 » en « 2018-05-09 ». Si on visualise les $\\alpha^{\\langle t, t' \\rangle}$ calculés, on obtient ceci :\n",
        "\n",
        "<img src=\"https://wiki.hacksmeta.com/static/images/ML/DL/attention/date_attention.png\" style=\"width:600;height:300px;\"> <br>\n",
        "<caption><center> **Figure 8** : Carte complète d’attention</center></caption>\n",
        "\n",
        "Remarquez comment la sortie ignore la partie « Saturday » de l’entrée. Aucun des pas de temps en sortie ne prête beaucoup d’attention à cette partie de l’entrée. On voit aussi que le 9 a été traduit en 09 et que May a été correctement traduit en 05, la sortie prêtant attention aux parties de l’entrée nécessaires pour faire la traduction. L’année nécessite surtout que le modèle prête attention au « 18 » dans l’entrée afin de générer « 2018 ».\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrP893IFh3Mv"
      },
      "source": [
        "<a name='3-1'></a>\n",
        "### 3.1 - Récupération des poids d’attention depuis le réseau\n",
        "\n",
        "Voyons maintenant comment visualiser les valeurs d’attention dans votre réseau. Nous allons faire passer un exemple à travers le réseau, puis visualiser les valeurs de $\\alpha^{\\langle t, t' \\rangle}$.\n",
        "\n",
        "Pour savoir où se trouvent les valeurs d’attention, commençons par afficher un résumé du modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfiLrfKIh3Mv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cbd4ee4-d993-46e8-fed7-b8829988c4df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ s0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m17,920\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m1\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m2\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m3\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m4\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m5\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m6\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m7\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m8\u001b[0m]… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ repeat_vector[\u001b[38;5;34m9\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │      \u001b[38;5;34m1,290\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ concatenate[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m11\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_weights   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ c0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m33,024\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ c0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m2\u001b[0m],       │\n",
              "│                     │                   │            │ dot[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │        \u001b[38;5;34m715\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ s0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>]… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_weights   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ attention_weight… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ c0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ c0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],       │\n",
              "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,882\u001b[0m (620.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,882</span> (620.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m105,922\u001b[0m (413.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,922</span> (413.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbcprBCPh3Mv"
      },
      "source": [
        "Parcourez la sortie de `model.summary()` ci-dessus. Vous pouvez voir que la couche nommée `attention_weights` produit les `alphas` de forme (m, 30, 1) avant que `dot_2` ne calcule le vecteur contexte pour chaque pas de temps $t = 0, \\ldots, T_y-1$. Allons récupérer les poids d’attention de cette couche.\n",
        "\n",
        "La fonction `attention_map()` extrait les valeurs d’attention de votre modèle et les affiche graphiquement.\n",
        "\n",
        "**Note** : Nous savons que vous pourriez rencontrer une erreur en exécutant la cellule ci-dessous malgré une implémentation correcte de l’Exercice 2 - `modelf` ci-dessus. Si vous avez cette erreur, merci de la signaler sur ce [Topic](https://discourse.deeplearning.ai/t/error-in-optional-ungraded-part-of-neural-machine-translation-w3a1/1096) sur [Discourse](https://discourse.deeplearning.ai), cela nous aidera à améliorer notre contenu.\n",
        "\n",
        "Si vous n’êtes pas encore inscrit dans notre communauté Discourse, vous pouvez le faire en cliquant sur ce lien : http://bit.ly/dls-discourse\n",
        "\n",
        "Et ne vous inquiétez pas pour l’erreur, elle n’impactera pas la notation de ce devoir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQPA084la19T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "ba743857-0377-428f-ae5d-ae18d27028f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-1099113797.py:226: RuntimeWarning: invalid value encountered in divide\n",
            "  attention_map = attention_map / row_max[:, None]\n",
            "/tmp/ipython-input-4-1099113797.py:232: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x850 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"friday 06 dec 1991\", num = 7, n_s = 64);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ3qbIjqh3Mx"
      },
      "source": [
        "Sur le graphique généré, vous pouvez observer les valeurs des poids d’attention pour chaque caractère de la sortie prédite. Examinez ce graphique et vérifiez que les endroits où le réseau porte son attention vous semblent cohérents.\n",
        "\n",
        "Dans l’application de traduction de dates, vous constaterez que la majorité du temps, l’attention aide à prédire l’année, et n’a pas autant d’impact pour prédire le jour ou le mois.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkpGu1Jkh3Mx"
      },
      "source": [
        "### Félicitations !\n",
        "\n",
        "Vous êtes arrivé à la fin de ce devoir.\n",
        "\n",
        "#### Voici ce que vous devez retenir\n",
        "\n",
        "- Les modèles de traduction automatique peuvent être utilisés pour transformer une séquence en une autre. Ils sont utiles non seulement pour traduire des langues humaines (comme du français vers l’anglais) mais aussi pour des tâches comme la traduction de formats de dates.\n",
        "- Un mécanisme d’attention permet à un réseau de se concentrer sur les parties les plus pertinentes de l’entrée lors de la production d’une partie spécifique de la sortie.\n",
        "- Un réseau utilisant un mécanisme d’attention peut traduire des entrées de longueur $T_x$ en sorties de longueur $T_y$, où $T_x$ et $T_y$ peuvent être différents.\n",
        "- Vous pouvez visualiser les poids d’attention $\\alpha^{\\langle t,t' \\rangle}$ pour voir où le réseau porte son attention lors de la génération de chaque sortie.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaKA2u4uh3My"
      },
      "source": [
        "Félicitations pour avoir terminé ce devoir ! Vous êtes désormais capable d’implémenter un modèle d’attention et de l’utiliser pour apprendre des correspondances complexes d’une séquence à une autre."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "DLSC5W3-1A"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}