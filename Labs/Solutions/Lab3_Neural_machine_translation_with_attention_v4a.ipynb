{"cells":[{"cell_type":"markdown","metadata":{"id":"TVIfK1kl_63k"},"source":["\u003e üìå **Avant de commencer :**\n","\u003e\n","\u003e [![Ouvrir dans Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ydDpKtNvZc7qCnC8LmSjcnLE9XsILjoM?usp=sharing)\n","\u003e\n","\u003e üîÅ *Veuillez faire une copie dans votre Google Drive (`Fichier \u003e Enregistrer une copie dans Drive`) avant toute modification.*\n"]},{"cell_type":"markdown","metadata":{"id":"adTDe2CTh3MU"},"source":["# Traduction Automatique Neuronale\n","\n","Bienvenue dans votre premier devoir de programmation de la semaine !\n","\n","* Vous allez construire un mod√®le de Traduction Automatique Neuronale (NMT) pour traduire des dates lisibles par l‚Äôhumain (\"25th of June, 2009\") en dates lisibles par une machine (\"2009-06-25\").\n","* Vous r√©aliserez cela en utilisant un mod√®le d‚Äôattention, l‚Äôun des mod√®les s√©quence-√†-s√©quence les plus sophistiqu√©s.\n"]},{"cell_type":"markdown","metadata":{"id":"0LCkjDBFh3Md"},"source":["## Table des mati√®res\n","\n","- [Packages](#0)\n","- [1 - Traduction des dates lisibles par l'humain en dates lisibles par la machine](#1)\n","    - [1.1 - Jeu de donn√©es](#1-1)\n","- [2 - Traduction automatique neuronale avec attention](#2)\n","    - [2.1 - M√©canisme d'attention](#2-1)\n","        - [Exercice 1 - one_step_attention](#ex-1)\n","        - [Exercice 2 - modelf](#ex-2)\n","        - [Exercice 3 - Compiler le mod√®le](#ex-3)\n","- [3 - Visualisation de l'attention (Optionnel / Non not√©)](#3)\n","    - [3.1 - Obtenir les poids d'attention du r√©seau](#3-1)\n"]},{"cell_type":"markdown","metadata":{"id":"tgMv5UYfu1ww"},"source":["## Installation des paquets"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31044,"status":"ok","timestamp":1752439837474,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"XQqRLiatu7-x","outputId":"654ec571-0d1e-4900-ffda-4f5e721b8ee0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faker\n","  Downloading faker-37.4.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (2.17.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Collecting evaluate\n","  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n","Requirement already satisfied: tensorboard\u003c2.19,\u003e=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy\u003c2.1.0,\u003e=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes\u003c0.5.0,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers\u003c0.22,\u003e=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors\u003e=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill\u003c0.3.8,\u003e=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec\u003e=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]\u003e=2021.11.1-\u003edatasets) (2025.3.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: scipy\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.45.1)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.4.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.7.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (6.6.3)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (0.3.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.20.1)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.30.0-\u003etransformers) (1.1.5)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2.4.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2025.7.9)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.1.3)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003edatasets) (2025.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (0.1.2)\n","Downloading faker-37.4.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faker, evaluate\n","Successfully installed evaluate-0.4.5 faker-37.4.0\n","Collecting solutions\n","  Downloading solutions-0.0.2.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: solutions\n","  Building wheel for solutions (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for solutions: filename=solutions-0.0.2-py3-none-any.whl size=3363 sha256=789e78c003ad750ca55b153c829cc0f449327a0ca3dff6280987ef051e87edfb\n","  Stored in directory: /root/.cache/pip/wheels/c4/75/b0/5ed63fec747fbdf70606f154524d0e1abb9ec159663c88b516\n","Successfully built solutions\n","Installing collected packages: solutions\n","Successfully installed solutions-0.0.2\n","Collecting testCase\n","  Downloading testcase-0.1.0-py3-none-any.whl.metadata (1.7 kB)\n","Downloading testcase-0.1.0-py3-none-any.whl (2.9 kB)\n","Installing collected packages: testCase\n","Successfully installed testCase-0.1.0\n"]}],"source":["! pip install faker babel tqdm tensorflow transformers datasets evaluate scikit-learn matplotlib\n","! pip install solutions\n","! pip install testCase"]},{"cell_type":"markdown","metadata":{"id":"4AG9JuVUa19L"},"source":["\u003ca name='0'\u003e\u003c/a\u003e\n","## Importation des paquets"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8083,"status":"ok","timestamp":1752439845573,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"RcBRMzPiiMmp"},"outputs":[],"source":["from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n","from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import load_model, Model\n","import tensorflow.keras.backend as K\n","import tensorflow as tf\n","import numpy as np\n","\n","from faker import Faker\n","import random\n","from tqdm import tqdm\n","from babel.dates import format_date\n","#from nmt_utils import *\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","from termcolor import colored\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.layers import ZeroPadding2D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import RepeatVector"]},{"cell_type":"markdown","metadata":{"id":"IM6SQ2TRtwC2"},"source":["## **Fonctions**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1752439845611,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"nmDnONGtt2F9"},"outputs":[],"source":["def generateTestCases():\n","\ttestCases = {\n","\t    'one_step_attention': {\n","\t        'partId': 'zcQIs',\n","\t        'testCases': [\n","\t            {\n","\t                'testInput': 0,\n","\t                'testOutput': m_out2\n","\t            }\n","\t        ]\n","\t    },\n","\t    'model': {\n","\t        'partId': 'PTKef',\n","\t        'testCases': [\n","\t            {\n","\t                'testInput': (Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size),\n","\t                'testOutput': m_out1\n","\t            }\n","\t        ]\n","\t    }\n","       }\n","\treturn testCases"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":143,"status":"ok","timestamp":1752439845765,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"pn8sV58Kt_qC"},"outputs":[],"source":["\n","fake = Faker()\n","Faker.seed(12345)\n","random.seed(12345)\n","\n","# Define format of the data we would like to generate\n","FORMATS = ['short',\n","           'medium',\n","           'long',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'd MMM YYY',\n","           'd MMMM YYY',\n","           'dd MMM YYY',\n","           'd MMM, YYY',\n","           'd MMMM, YYY',\n","           'dd, MMM YYY',\n","           'd MM YY',\n","           'd MMMM YYY',\n","           'MMMM d YYY',\n","           'MMMM d, YYY',\n","           'dd.MM.YY']\n","\n","# change this if you want it to work with another language\n","LOCALES = ['en_US']\n","\n","def load_date():\n","    \"\"\"\n","        Loads some fake dates\n","        :returns: tuple containing human readable string, machine readable string, and date object\n","    \"\"\"\n","    dt = fake.date_object()\n","\n","    try:\n","        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US') # locale=random.choice(LOCALES))\n","        human_readable = human_readable.lower()\n","        human_readable = human_readable.replace(',','')\n","        machine_readable = dt.isoformat()\n","\n","    except AttributeError as e:\n","        return None, None, None\n","\n","    return human_readable, machine_readable, dt\n","\n","def load_dataset(m):\n","    \"\"\"\n","        Loads a dataset with m examples and vocabularies\n","        :m: the number of examples to generate\n","    \"\"\"\n","\n","    human_vocab = set()\n","    machine_vocab = set()\n","    dataset = []\n","    Tx = 30\n","\n","\n","    for i in tqdm(range(m)):\n","        h, m, _ = load_date()\n","        if h is not None:\n","            dataset.append((h, m))\n","            human_vocab.update(tuple(h))\n","            machine_vocab.update(tuple(m))\n","\n","    human = dict(zip(sorted(human_vocab) + ['\u003cunk\u003e', '\u003cpad\u003e'],\n","                     list(range(len(human_vocab) + 2))))\n","    inv_machine = dict(enumerate(sorted(machine_vocab)))\n","    machine = {v:k for k,v in inv_machine.items()}\n","\n","    return dataset, human, machine, inv_machine\n","\n","def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n","\n","    X, Y = zip(*dataset)\n","\n","    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n","    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n","\n","    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n","    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n","\n","\n","\n","    return X, np.array(Y), Xoh, Yoh\n","\n","def string_to_int(string, length, vocab):\n","    \"\"\"\n","    Converts all strings in the vocabulary into a list of integers representing the positions of the\n","    input string's characters in the \"vocab\"\n","\n","    Arguments:\n","    string -- input string, e.g. 'Wed 10 Jul 2007'\n","    length -- the number of time steps you'd like, determines if the output will be padded or cut\n","    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n","\n","    Returns:\n","    rep -- list of integers (or '\u003cunk\u003e') (size = length) representing the position of the string's character in the vocabulary\n","    \"\"\"\n","\n","    #make lower to standardize\n","    string = string.lower()\n","    string = string.replace(',','')\n","\n","    if len(string) \u003e length:\n","        string = string[:length]\n","\n","    rep = list(map(lambda x: vocab.get(x, '\u003cunk\u003e'), string))\n","\n","    if len(string) \u003c length:\n","        rep += [vocab['\u003cpad\u003e']] * (length - len(string))\n","\n","    #print (rep)\n","    return rep\n","\n","\n","def int_to_string(ints, inv_vocab):\n","    \"\"\"\n","    Output a machine readable list of characters based on a list of indexes in the machine's vocabulary\n","\n","    Arguments:\n","    ints -- list of integers representing indexes in the machine's vocabulary\n","    inv_vocab -- dictionary mapping machine readable indexes to machine readable characters\n","\n","    Returns:\n","    l -- list of characters corresponding to the indexes of ints thanks to the inv_vocab mapping\n","    \"\"\"\n","\n","    l = [inv_vocab[i] for i in ints]\n","    return l\n","\n","\n","EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n","\n","def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n","    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n","    prediction = model.predict(np.array([encoded]))\n","    prediction = np.argmax(prediction[0], axis=-1)\n","    return int_to_string(prediction, inv_output_vocabulary)\n","\n","def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n","    predicted = []\n","    for example in examples:\n","        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n","        print('input:', example)\n","        print('output:', predicted[-1])\n","    return predicted\n","\n","\n","\n","def softmax(x, axis=1):\n","    \"\"\"Softmax activation function.\n","    # Arguments\n","        x : Tensor.\n","        axis: Integer, axis along which the softmax normalization is applied.\n","    # Returns\n","        Tensor, output of softmax transformation.\n","    # Raises\n","        ValueError: In case `dim(x) == 1`.\n","    \"\"\"\n","    ndim = K.ndim(x)\n","    if ndim == 2:\n","        return K.softmax(x)\n","    elif ndim \u003e 2:\n","        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n","        s = K.sum(e, axis=axis, keepdims=True)\n","        return e / s\n","    else:\n","        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n","\n","\n","def plot_attention_map(modelx, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 7):\n","    \"\"\"\n","    Plot the attention map.\n","\n","    \"\"\"\n","    attention_map = np.zeros((10, 30))\n","    layer = modelx.get_layer('attention_weights')\n","\n","    Ty, Tx = attention_map.shape\n","\n","    human_vocab_size = 37\n","\n","    # Well, this is cumbersome but this version of tensorflow-keras has a bug that affects the\n","    # reuse of layers in a model with the functional API.\n","    # So, I have to recreate the model based on the functional\n","    # components and connect then one by one.\n","    # ideally it can be done simply like this:\n","    # layer = modelx.layers[num]\n","    # f = Model(modelx.inputs, [layer.get_output_at(t) for t in range(Ty)])\n","    #\n","\n","    X = modelx.inputs[0]\n","    s0 = modelx.inputs[1]\n","    c0 = modelx.inputs[2]\n","    s = s0\n","    c = s0\n","\n","    a = modelx.layers[2](X)\n","    outputs = []\n","\n","    for t in range(Ty):\n","        s_prev = s\n","        s_prev = modelx.layers[3](s_prev)\n","        concat = modelx.layers[4]([a, s_prev])\n","        e = modelx.layers[5](concat)\n","        energies = modelx.layers[6](e)\n","        alphas = modelx.layers[7](energies)\n","        context = modelx.layers[8]([alphas, a])\n","        # Don't forget to pass: initial_state = [hidden state, cell state] (‚âà 1 line)\n","        s, _, c = modelx.layers[10](context, initial_state = [s, c])\n","        outputs.append(energies)\n","\n","    f = Model(inputs=[X, s0, c0], outputs = outputs)\n","\n","\n","    s0 = np.zeros((1, n_s))\n","    c0 = np.zeros((1, n_s))\n","    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n","    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n","\n","\n","    r = f([encoded, s0, c0])\n","\n","    for t in range(Ty):\n","        for t_prime in range(Tx):\n","            attention_map[t][t_prime] = r[t][0, t_prime]\n","\n","    # Normalize attention map\n","    row_max = attention_map.max(axis=1)\n","    attention_map = attention_map / row_max[:, None]\n","\n","    prediction = modelx.predict([encoded, s0, c0])\n","\n","    predicted_text = []\n","    for i in range(len(prediction)):\n","        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n","\n","    predicted_text = list(predicted_text)\n","    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n","    text_ = list(text)\n","\n","    # get the lengths of the string\n","    input_length = len(text)\n","    output_length = Ty\n","\n","    # Plot the attention_map\n","    plt.clf()\n","    f = plt.figure(figsize=(8, 8.5))\n","    ax = f.add_subplot(1, 1, 1)\n","\n","    # add image\n","    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n","\n","    # add colorbar\n","    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n","    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n","    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n","\n","    # add labels\n","    ax.set_yticks(range(output_length))\n","    ax.set_yticklabels(predicted_text[:output_length])\n","\n","    ax.set_xticks(range(input_length))\n","    ax.set_xticklabels(text_[:input_length], rotation=45)\n","\n","    ax.set_xlabel('Input Sequence')\n","    ax.set_ylabel('Output Sequence')\n","\n","    # add grid and legend\n","    ax.grid()\n","\n","    #f.show()\n","\n","    return attention_map"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1752439845812,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"1qQl22RauLmz"},"outputs":[],"source":["# Compare the two inputs\n","def comparator(learner, instructor):\n","    if len(learner) != len(instructor):\n","        raise AssertionError(\"Error in test. The lists contain a different number of elements\")\n","    for index, a in enumerate(instructor):\n","        b = learner[index]\n","        if tuple(a) != tuple(b):\n","            print(colored(f\"Test failed at index {index}\", attrs=['bold']),\n","                  \"\\n Expected value \\n\\n\", colored(f\"{a}\", \"green\"),\n","                  \"\\n\\n does not match the input value: \\n\\n\",\n","                  colored(f\"{b}\", \"red\"))\n","            raise AssertionError(\"Error in test\")\n","    print(colored(\"All tests passed!\", \"green\"))\n","\n","# extracts the description of a given model\n","def summary(model):\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    result = []\n","    for layer in model.layers:\n","        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n","        if (type(layer) == Conv2D):\n","            descriptors.append(layer.padding)\n","            descriptors.append(layer.activation.__name__)\n","            descriptors.append(layer.kernel_initializer.__class__.__name__)\n","        if (type(layer) == MaxPooling2D):\n","            descriptors.append(layer.pool_size)\n","            descriptors.append(layer.strides)\n","            descriptors.append(layer.padding)\n","        if (type(layer) == Dropout):\n","            descriptors.append(layer.rate)\n","        if (type(layer) == ZeroPadding2D):\n","            descriptors.append(layer.padding)\n","        if (type(layer) == Dense):\n","            descriptors.append(layer.activation.__name__)\n","        if (type(layer) == LSTM):\n","            descriptors.append(layer.input_shape)\n","            descriptors.append(layer.activation.__name__)\n","        if (type(layer) == RepeatVector):\n","            descriptors.append(layer.n)\n","        result.append(descriptors)\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"J0pkH-k0h3Mf"},"source":["\u003ca name='1'\u003e\u003c/a\u003e  \n","## 1 - Traduction des dates lisibles par l‚Äôhumain en dates lisibles par la machine\n","\n","* Le mod√®le que vous allez construire ici pourrait √™tre utilis√© pour traduire d‚Äôune langue √† une autre, par exemple de l‚Äôanglais vers l‚Äôhindi.  \n","* Cependant, la traduction automatique n√©cessite des jeux de donn√©es massifs et prend g√©n√©ralement plusieurs jours d‚Äôentra√Ænement sur GPU.  \n","* Pour vous offrir un terrain d‚Äôexp√©rimentation avec ces mod√®les sans utiliser de tr√®s grands jeux de donn√©es, nous allons effectuer une t√¢che plus simple de ¬´ traduction de dates ¬ª.  \n","* Le r√©seau prendra en entr√©e une date √©crite dans diff√©rents formats possibles (*par exemple : \"le 29 ao√ªt 1958\", \"30/03/1968\", \"24 JUIN 1987\"*).  \n","* Le r√©seau traduira ces formats en dates standardis√©es et lisibles par une machine (*par exemple : \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"*).  \n","* Nous apprendrons au r√©seau √† produire les dates dans le format commun lisible par machine : AAAA-MM-JJ.\n","\n","\u003c!--\n","Prenez un moment pour jeter un ≈ìil √† [nmt_utils.py](./nmt_utils.py) pour voir tous les formats. Comptez et comprenez comment les formats fonctionnent, vous aurez besoin de cette connaissance plus tard. !--\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"8BhEaJvph3Mf"},"source":["\u003ca name='1-1'\u003e\u003c/a\u003e  \n","### 1.1 - Jeu de donn√©es\n","\n","Nous allons entra√Æner le mod√®le sur un jeu de donn√©es contenant 10 000 dates lisibles par l‚Äôhumain ainsi que leurs √©quivalents standardis√©s et lisibles par la machine.  \n","Ex√©cutons les cellules suivantes pour charger le jeu de donn√©es et afficher quelques exemples.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1752439965353,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"gwIf5l17h3Mg","outputId":"111be631-102f-4f81-f40f-ddb6a7ff3397"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00\u003c00:00, 25371.76it/s]\n"]}],"source":["m = 10000\n","dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1752439967656,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"zCTqMyPch3Mg","outputId":"b82a42ee-e6c4-43c6-8c6a-9df850772f72"},"outputs":[{"data":{"text/plain":["[('19 feb 1993', '1993-02-19'),\n"," ('26.07.70', '1970-07-26'),\n"," ('10/29/15', '2015-10-29'),\n"," ('saturday august 2 1986', '1986-08-02'),\n"," ('sunday june 17 1990', '1990-06-17'),\n"," ('friday october 3 1980', '1980-10-03'),\n"," ('thursday june 7 2001', '2001-06-07'),\n"," ('24 dec 1978', '1978-12-24'),\n"," ('25 nov 1976', '1976-11-25'),\n"," ('sunday january 16 1994', '1994-01-16')]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset[:10]"]},{"cell_type":"markdown","metadata":{"id":"ao4Ffrkxh3Mg"},"source":["Vous avez charg√© :  \n","- `dataset` : une liste de tuples (date lisible par l‚Äôhumain, date lisible par la machine).  \n","- `human_vocab` : un dictionnaire Python mappant tous les caract√®res utilis√©s dans les dates lisibles par l‚Äôhumain √† un indice entier.  \n","- `machine_vocab` : un dictionnaire Python mappant tous les caract√®res utilis√©s dans les dates lisibles par la machine √† un indice entier.  \n","    - **Remarque** : ces indices ne sont pas forc√©ment les m√™mes que ceux de `human_vocab`.  \n","- `inv_machine_vocab` : le dictionnaire inverse de `machine_vocab`, qui mappe les indices vers les caract√®res.\n","\n","Pr√©traitons maintenant les donn√©es pour convertir les textes bruts en indices.  \n","- Nous fixons Tx = 30  \n","    - Tx correspond √† la longueur maximale d‚Äôune date lisible par l‚Äôhumain.  \n","    - Si une entr√©e est plus longue, elle sera tronqu√©e.  \n","- Nous fixons Ty = 10  \n","    - Le format \"AAAA-MM-JJ\" fait 10 caract√®res.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1752440002489,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"Qdso90EBh3Mg","outputId":"f3826cbd-c409-4ba9-dc9c-67c42924471f"},"outputs":[{"name":"stdout","output_type":"stream","text":["X.shape: (10000, 30)\n","Y.shape: (10000, 10)\n","Xoh.shape: (10000, 30, 37)\n","Yoh.shape: (10000, 10, 11)\n"]}],"source":["Tx = 30\n","Ty = 10\n","X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n","\n","print(\"X.shape:\", X.shape)\n","print(\"Y.shape:\", Y.shape)\n","print(\"Xoh.shape:\", Xoh.shape)\n","print(\"Yoh.shape:\", Yoh.shape)"]},{"cell_type":"markdown","metadata":{"id":"q9C0UY25h3Mh"},"source":["Vous avez maintenant :  \n","- `X` : une version pr√©trait√©e des dates lisibles par l‚Äôhumain dans le jeu d‚Äôentra√Ænement.  \n","    - Chaque caract√®re dans `X` est remplac√© par un indice (entier) mapp√© au caract√®re via `human_vocab`.  \n","    - Chaque date est compl√©t√©e par un padding pour assurer une longueur de $T_x$, √† l‚Äôaide d‚Äôun caract√®re sp√©cial (\u003cpad\u003e).  \n","    - `X.shape = (m, Tx)` o√π `m` est le nombre d‚Äôexemples dans le batch d‚Äôentra√Ænement.  \n","\n","- `Y` : une version pr√©trait√©e des dates lisibles par la machine dans le jeu d‚Äôentra√Ænement.  \n","    - Chaque caract√®re est remplac√© par l‚Äôindice correspondant dans `machine_vocab`.  \n","    - `Y.shape = (m, Ty)`.  \n","\n","- `Xoh` : version one-hot de `X`  \n","    - Chaque indice dans `X` est converti en repr√©sentation one-hot (si l‚Äôindice est 2, la position 2 dans le vecteur one-hot vaut 1, les autres positions valent 0).  \n","    - `Xoh.shape = (m, Tx, len(human_vocab))`.  \n","\n","- `Yoh` : version one-hot de `Y`  \n","    - Chaque indice dans `Y` est converti en repr√©sentation one-hot.  \n","    - `Yoh.shape = (m, Ty, len(machine_vocab))`.  \n","    - `len(machine_vocab) = 11` car il y a 10 chiffres (0 √† 9) plus le symbole `-`.\n"]},{"cell_type":"markdown","metadata":{"id":"N7qKvWrTh3Mh"},"source":["* Regardons √©galement quelques exemples d‚Äôexemples d‚Äôentra√Ænement pr√©trait√©s.  \n","* N‚Äôh√©sitez pas √† modifier la valeur de `index` dans la cellule ci-dessous pour parcourir le jeu de donn√©es et voir comment les dates source/cible sont pr√©trait√©es.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1752440004900,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"kUOayR4gh3Mh","outputId":"a51fb277-10fd-48eb-f214-2ec22d195ba6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date source : 19 feb 1993\n","Date cible : 1993-02-19\n","\n","Date source apr√®s pr√©traitement (indices) : [ 4 12  0 18 17 14  0  4 12 12  6 36 36 36 36 36 36 36 36 36 36 36 36 36\n"," 36 36 36 36 36 36]\n","Date cible apr√®s pr√©traitement (indices) : [ 2 10 10  4  0  1  3  0  2 10]\n","\n","Date source apr√®s pr√©traitement (one-hot) : [[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n","Date cible apr√®s pr√©traitement (one-hot) : [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"]}],"source":["index = 0\n","print(\"Date source :\", dataset[index][0])\n","print(\"Date cible :\", dataset[index][1])\n","print()\n","print(\"Date source apr√®s pr√©traitement (indices) :\", X[index])\n","print(\"Date cible apr√®s pr√©traitement (indices) :\", Y[index])\n","print()\n","print(\"Date source apr√®s pr√©traitement (one-hot) :\", Xoh[index])\n","print(\"Date cible apr√®s pr√©traitement (one-hot) :\", Yoh[index])"]},{"cell_type":"markdown","metadata":{"id":"94o4RYbOh3Mi"},"source":["\u003ca name='2'\u003e\u003c/a\u003e  \n","## 2 - Traduction automatique neuronale avec attention\n","\n","* Si vous deviez traduire un paragraphe d‚Äôun livre du fran√ßais vers l‚Äôanglais, vous ne liriez pas tout le paragraphe, puis fermeriez le livre avant de traduire.  \n","* M√™me pendant la traduction, vous liriez et reliriez certaines parties, en vous concentrant sur les passages fran√ßais correspondant √† ceux de l‚Äôanglais que vous √©crivez.  \n","* Le m√©canisme d‚Äôattention indique √† un mod√®le de traduction automatique neuronale o√π il doit porter son attention √† chaque √©tape.\n","\n","\u003ca name='2-1'\u003e\u003c/a\u003e  \n","### 2.1 - M√©canisme d‚Äôattention\n","\n","Dans cette partie, vous allez impl√©menter le m√©canisme d‚Äôattention pr√©sent√© dans les vid√©os de cours.  \n","* Voici une figure pour vous rappeler le fonctionnement du mod√®le.  \n","  * Le sch√©ma de gauche montre le mod√®le d‚Äôattention.  \n","  * Le sch√©ma de droite montre ce que fait une √©tape d‚Äô¬´ attention ¬ª pour calculer les variables d‚Äôattention $\\alpha^{\\langle t, t' \\rangle}$.  \n","  * Ces variables $\\alpha^{\\langle t, t' \\rangle}$ sont utilis√©es pour calculer la variable contexte $context^{\\langle t \\rangle}$ √† chaque pas de temps en sortie ($t=1, \\ldots, T_y$).\n","\n","\n","\u003ctable\u003e\n","\u003ctd\u003e\n","\u003cimg src=\"https://images2018.cnblogs.com/blog/937910/201804/937910-20180408225129369-1491566692.png\" style=\"width:500;height:500px;\"\u003e \u003cbr\u003e\n","\u003c/td\u003e\n","\u003ctd\u003e\n","\u003cimg src=\"https://images2018.cnblogs.com/blog/937910/201804/937910-20180408232000910-186858891.png\" style=\"width:500;height:500px;\"\u003e \u003cbr\u003e\n","\u003c/td\u003e\n","\u003c/table\u003e\n","\u003ccaption\u003e\u003ccenter\u003e **Figure 1** : Traduction automatique neuronale avec attention\u003c/center\u003e\u003c/caption\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"b2TkQnykh3Mi"},"source":["Voici quelques propri√©t√©s du mod√®le que vous pouvez remarquer :\n","\n","#### LSTMs avant et apr√®s l‚Äôattention de chaque c√¥t√© du m√©canisme d‚Äôattention\n","\n","- Il y a deux LSTMs distincts dans ce mod√®le (voir le diagramme √† gauche) : les LSTMs *avant* l‚Äôattention et *apr√®s* l‚Äôattention.  \n","- La Bi-LSTM *avant l‚Äôattention* est celle en bas de l‚Äôimage, c‚Äôest une LSTM bidirectionnelle et elle se situe *avant* le m√©canisme d‚Äôattention.  \n","    - Le m√©canisme d‚Äôattention est montr√© au centre du diagramme de gauche.  \n","    - La Bi-LSTM avant attention s‚Äô√©tend sur $T_x$ pas de temps.  \n","- La LSTM *apr√®s l‚Äôattention* est en haut du diagramme et se situe *apr√®s* le m√©canisme d‚Äôattention.  \n","    - La LSTM apr√®s attention s‚Äô√©tend sur $T_y$ pas de temps.  \n","\n","- La LSTM apr√®s attention transmet l‚Äô√©tat cach√© $s^{\\langle t \\rangle}$ et l‚Äô√©tat de la cellule $c^{\\langle t \\rangle}$ d‚Äôun pas de temps au suivant.\n"]},{"cell_type":"markdown","metadata":{"id":"JpznWuWqh3Mi"},"source":["#### Une LSTM poss√®de √† la fois un √©tat cach√© et un √©tat de cellule\n","* Dans les vid√©os de cours, nous utilisions uniquement un RNN basique pour le mod√®le de s√©quence apr√®s l‚Äôattention  \n","  * Cela signifie que l‚Äô√©tat captur√© par le RNN ne sortait que l‚Äô√©tat cach√© $s^{\\langle t\\rangle}$.  \n","* Dans ce devoir, nous utilisons une LSTM au lieu d‚Äôun RNN basique.  \n","  * Donc la LSTM poss√®de √† la fois l‚Äô√©tat cach√© $s^{\\langle t\\rangle}$ et l‚Äô√©tat de cellule $c^{\\langle t\\rangle}$.  \n"]},{"cell_type":"markdown","metadata":{"id":"85btUzl4h3Mj"},"source":["#### Chaque pas de temps n‚Äôutilise pas les pr√©dictions du pas de temps pr√©c√©dent\n","* Contrairement aux exemples pr√©c√©dents de g√©n√©ration de texte vus plus t√¥t dans le cours, dans ce mod√®le, la LSTM apr√®s attention au temps $t$ ne prend pas comme entr√©e la pr√©diction du pas de temps pr√©c√©dent $y^{\\langle t-1 \\rangle}$.  \n","* La LSTM apr√®s attention au temps $t$ prend uniquement comme entr√©e l‚Äô√©tat cach√© $s^{\\langle t\\rangle}$ et l‚Äô√©tat de cellule $c^{\\langle t\\rangle}$.  \n","* Nous avons con√ßu le mod√®le ainsi parce que, contrairement √† la g√©n√©ration de langage (o√π les caract√®res adjacents sont fortement corr√©l√©s), il n‚Äôy a pas une d√©pendance aussi forte entre le caract√®re pr√©c√©dent et le caract√®re suivant dans une date au format YYYY-MM-DD.\n"]},{"cell_type":"markdown","metadata":{"id":"NYT3v7rUh3Mk"},"source":["#### Concatenation des √©tats cach√©s des LSTMs avant attention avant et arri√®re\n","\n","- $\\overrightarrow{a}^{\\langle t \\rangle}$ : √©tat cach√© de la LSTM avant attention en direction avant.  \n","- $\\overleftarrow{a}^{\\langle t \\rangle}$ : √©tat cach√© de la LSTM avant attention en direction arri√®re.  \n","- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$ : concat√©nation des activations des directions avant $\\overrightarrow{a}^{\\langle t \\rangle}$ et arri√®re $\\overleftarrow{a}^{\\langle t \\rangle}$ de la Bi-LSTM avant attention.  \n"]},{"cell_type":"markdown","metadata":{"id":"97GUKCqwh3Mk"},"source":["#### Calcul des \"√©nergies\" $e^{\\langle t, t' \\rangle}$ en fonction de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t' \\rangle}$\n","\n","- Rappel dans les vid√©os de cours \"Attention Model\", de 6:45 √† 8:16, la d√©finition de \"e\" comme fonction de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$.  \n","    - \"e\" est appel√©e la variable des \"√©nergies\".  \n","    - $s^{\\langle t-1 \\rangle}$ est l'√©tat cach√© de la LSTM post-attention.  \n","    - $a^{\\langle t' \\rangle}$ est l'√©tat cach√© de la LSTM pr√©-attention.  \n","    - $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$ sont entr√©s dans un r√©seau de neurones simple, qui apprend la fonction pour produire $e^{\\langle t, t' \\rangle}$.  \n","    - $e^{\\langle t, t' \\rangle}$ est ensuite utilis√© pour calculer l'attention $\\alpha^{\\langle t, t' \\rangle}$ que $y^{\\langle t \\rangle}$ doit porter √† $a^{\\langle t' \\rangle}$.  \n"]},{"cell_type":"markdown","metadata":{"id":"scu_HnPNh3Mk"},"source":["- Le diagramme √† droite de la figure 1 utilise un n≈ìud `RepeatVector` pour copier la valeur de $s^{\\langle t-1 \\rangle}$ $T_x$ fois.  \n","- Ensuite, il utilise une op√©ration de `Concatenation` pour concat√©ner $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$.  \n","- La concat√©nation de $s^{\\langle t-1 \\rangle}$ et $a^{\\langle t \\rangle}$ est entr√©e dans une couche \"Dense\", qui calcule $e^{\\langle t, t' \\rangle}$.  \n","- $e^{\\langle t, t' \\rangle}$ est ensuite pass√©e √† travers une fonction softmax pour calculer $\\alpha^{\\langle t, t' \\rangle}$.  \n","- Notez que le diagramme ne montre pas explicitement la variable $e^{\\langle t, t' \\rangle}$, mais elle se trouve au-dessus de la couche Dense et en dessous de la couche Softmax dans la partie droite de la figure 1.  \n","- Nous expliquerons ci-dessous comment utiliser `RepeatVector` et `Concatenation` dans Keras.  \n"]},{"cell_type":"markdown","metadata":{"id":"_ukmqe_Yh3Ml"},"source":["#### D√©tails d'impl√©mentation\n","\n","Impl√©mentons ce traducteur neuronal. Vous commencerez par impl√©menter deux fonctions : `one_step_attention()` et `model()`.\n","\n","#### one_step_attention\n","* Les entr√©es de la fonction `one_step_attention` au pas de temps $t$ sont :\n","    - $[a^{\u003c1\u003e},a^{\u003c2\u003e}, ..., a^{\u003cT_x\u003e}]$ : tous les √©tats cach√©s du Bi-LSTM pr√©-attention.\n","    - $s^{\u003ct-1\u003e}$ : l'√©tat cach√© pr√©c√©dent du LSTM post-attention.\n","* La fonction `one_step_attention` calcule :\n","    - $[\\alpha^{\u003ct,1\u003e},\\alpha^{\u003ct,2\u003e}, ..., \\alpha^{\u003ct,T_x\u003e}]$ : les poids d'attention,\n","    - $context^{ \\langle t \\rangle }$ : le vecteur de contexte :\n","    \n","$$\n","context^{\u003ct\u003e} = \\sum_{t' = 1}^{T_x} \\alpha^{\u003ct,t'\u003e}a^{\u003ct'\u003e} \\tag{1}\n","$$\n","\n","##### Clarification sur 'context' et 'c'\n","- Dans les vid√©os de cours, le contexte √©tait not√© $c^{\\langle t \\rangle}$.\n","- Dans ce devoir, nous appelons le contexte $context^{\\langle t \\rangle}$.\n","    - Ceci afin d'√©viter toute confusion avec la cellule m√©moire interne du LSTM post-attention, qui est aussi not√©e $c^{\\langle t \\rangle}$.\n"]},{"cell_type":"markdown","metadata":{"id":"LIfLKkwoh3Ml"},"source":["\u003ca name='ex-1'\u003e\u003c/a\u003e\n","### Exercice 1 - one_step_attention\n","\n","Impl√©mentez la fonction `one_step_attention()`.\n","\n","* La fonction `model()` appellera les couches dans `one_step_attention()` $T_y$ fois √† l‚Äôaide d‚Äôune boucle `for`.\n","* Il est important que les $T_y$ copies partagent les **m√™mes poids** :\n","    * Les poids **ne doivent pas √™tre r√©initialis√©s** √† chaque appel.\n","    * Autrement dit, toutes les √©tapes $T_y$ doivent **partager les m√™mes poids**.\n","\n","#### Comment faire en sorte que les poids soient partag√©s dans Keras :\n","1. D√©finissez les objets de couche dans un **scope global**, c‚Äôest-√†-dire **en dehors de la fonction** `one_step_attention`.  \n","   - Par exemple, les d√©finir en tant que variables **globales** fonctionnera.\n","   - Note : les d√©finir √† l‚Äôint√©rieur de la fonction `model()` fonctionnerait techniquement, puisque `model` appelle ensuite `one_step_attention`.  \n","     Mais pour des raisons de **correction automatique**, nous vous demandons de les d√©finir globalement.\n","\n","2. Appelez ces objets √† chaque propagation de l‚Äôentr√©e dans la fonction.\n","\n","* Nous avons d√©j√† d√©fini les couches n√©cessaires en tant que **variables globales**.\n","    * Veuillez ex√©cuter les cellules fournies pour les cr√©er.\n","    * **Ne changez pas les noms des variables**, car le correcteur automatique les attend avec les noms exacts fournis.\n","\n","---\n","\n","#### Documentation Keras des couches utilis√©es :\n","\n"," * [RepeatVector()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector)  \n","```python\n","var_repeated = repeat_layer(var1)\n","```\n"," * [Concatenate()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)   \n","```Python\n","concatenated_vars = concatenate_layer([var1,var2,var3])\n","```\n"," * [Dense()](https://keras.io/layers/core/#dense)  \n","```Python\n","var_out = dense_layer(var_in)\n","```\n"," * [Activation()](https://keras.io/layers/core/#activation)  \n","```Python\n","activation = activation_layer(var_in)  \n","```\n"," * [Dot()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot)  \n","```Python\n","dot_product = dot_layer([var1,var2])\n","```\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1752440189950,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"Cvop5Apyh3Mm"},"outputs":[],"source":["# Couches partag√©es d√©finies comme variables globales\n","repeator = RepeatVector(Tx)\n","concatenator = Concatenate(axis=-1)\n","densor1 = Dense(10, activation = \"tanh\")\n","densor2 = Dense(1, activation = \"relu\")\n","activator = Activation(softmax, name='attention_weights')  # Nous utilisons une fonction softmax personnalis√©e (axis = 1) charg√©e dans ce notebook\n","dotor = Dot(axes = 1)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":118,"status":"ok","timestamp":1752440194880,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"Nmkos-HWiuSP"},"outputs":[],"source":["# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n","# GRADED FUNCTION: one_step_attention\n","\n","def one_step_attention(a, s_prev):\n","    \"\"\"\n","    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n","    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n","\n","    Arguments:\n","    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n","    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n","\n","    Returns:\n","    context -- context vector, input of the next (post-attention) LSTM cell\n","    \"\"\"\n","\n","    ### START CODE HERE ###\n","    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (‚âà 1 line)\n","    s_prev = repeator(s_prev)\n","    # Use concatenator to concatenate a and s_prev on the last axis (‚âà 1 line)\n","    # For grading purposes, please list 'a' first and 's_prev' second, in this order.\n","    concat = concatenator([a, s_prev])\n","    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (‚âà1 lines)\n","    e = densor1(concat)\n","    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (‚âà1 lines)\n","    energies = densor2(e)\n","    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (‚âà 1 line)\n","    alphas = activator(energies)\n","    # Use dotor together with \"alphas\" and \"a\", in this order, to compute the context vector to be given to the next (post-attention) LSTM-cell (‚âà 1 line)\n","    context = dotor([alphas,a])\n","    ### END CODE HERE ###\n","\n","    return context"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1752440200763,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"iCwF7TqliV5P","outputId":"2c853c36-b8b6-4b50-994e-f50f2a982c53"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92mTous les tests ont r√©ussi !\n"]}],"source":["# TEST UNITAIRE\n","def one_step_attention_test(target):\n","\n","    m = 10\n","    Tx = 30\n","    n_a = 32\n","    n_s = 64\n","    #np.random.seed(10)\n","    a = np.random.uniform(1, 0, (m, Tx, 2 * n_a)).astype(np.float32)\n","    s_prev = np.random.uniform(1, 0, (m, n_s)).astype(np.float32) * 1\n","    context = target(a, s_prev)\n","\n","    #assert type(context) == tf.python.framework.ops.EagerTensor, \"Type inattendu. Il devrait s‚Äôagir d‚Äôun tenseur\"\n","    assert tuple(context.shape) == (m, 1, n_s), \"Forme de sortie inattendue\"\n","    assert np.all(context.numpy() \u003e 0), \"Toutes les valeurs de sortie doivent √™tre \u003e 0 dans cet exemple\"\n","    assert np.all(context.numpy() \u003c 1), \"Toutes les valeurs de sortie doivent √™tre \u003c 1 dans cet exemple\"\n","\n","    #assert np.allclose(context[0][0][0:5].numpy(), [0.50877404, 0.57160693, 0.45448175, 0.50074816, 0.53651875]), \"Valeurs inattendues dans le r√©sultat\"\n","    print(\"\\033[92mTous les tests ont r√©ussi !\")\n","\n","one_step_attention_test(one_step_attention)\n"]},{"cell_type":"markdown","metadata":{"id":"vcmC3WcQh3Mn"},"source":["\u003ca name='ex-2'\u003e\u003c/a\u003e  \n","### Exercice 2 - `modelf`\n","\n","Impl√©mentez `modelf()` comme expliqu√© dans la figure 1 et selon les instructions suivantes :\n","\n","* `modelf` fait d‚Äôabord passer l‚Äôentr√©e √† travers une Bi-LSTM pour obtenir $[a^{\u003c1\u003e},a^{\u003c2\u003e}, ..., a^{\u003cT_x\u003e}]$.\n","* Ensuite, `modelf` appelle `one_step_attention()` $T_y$ fois √† l‚Äôaide d‚Äôune boucle `for`. √Ä chaque it√©ration de cette boucle :\n","  - Il fournit le vecteur de contexte calcul√© $context^{\u003ct\u003e}$ √† la LSTM post-attention.\n","  - Il fait passer la sortie de la LSTM post-attention √† travers une couche dense avec une activation softmax.\n","  - Le softmax g√©n√®re une pr√©diction $\\hat{y}^{\u003ct\u003e}$.\n","\n","Encore une fois, nous avons d√©fini des **couches globales** avec partage de poids qui seront utilis√©es dans `modelf()`.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1752440208776,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"5RHgmZrVh3Mo"},"outputs":[],"source":["n_a = 32  # nombre d'unit√©s pour l'√©tat cach√© 'a' de la Bi-LSTM (pr√©-attention)\n","n_s = 64  # nombre d'unit√©s pour l'√©tat cach√© \"s\" de la LSTM post-attention\n","\n","# Veuillez noter qu'il s'agit de la cellule LSTM post-attention.\n","post_activation_LSTM_cell = LSTM(n_s, return_state=True)  # Veuillez ne pas modifier cette variable globale.\n","output_layer = Dense(len(machine_vocab), activation=softmax)"]},{"cell_type":"markdown","metadata":{"id":"lGkKpb1Nh3Mo"},"source":["Vous pouvez maintenant utiliser ces couches $T_y$ fois dans une boucle `for` pour g√©n√©rer les sorties, et leurs param√®tres ne seront pas r√©initialis√©s. Vous devrez effectuer les √©tapes suivantes :\n","\n","1. Propager l'entr√©e `X` dans une LSTM bidirectionnelle.  \n","   * [Bidirectional](https://keras.io/layers/wrappers/#bidirectional)  \n","   * [LSTM](https://keras.io/layers/recurrent/#lstm)  \n","   * N'oubliez pas que nous voulons que la LSTM retourne une s√©quence compl√®te et non seulement le dernier √©tat cach√©.  \n","\n","Exemple de code :\n","\n","```Python\n","sequence_of_hidden_states = Bidirectional(LSTM(units=..., return_sequences=...))(the_input_X)\n","```\n","    \n","2. It√©rer pour $t = 0, \\cdots, T_y-1$ :  \n","    1. Appeler `one_step_attention()`, en passant la s√©quence des √©tats cach√©s $[a^{\\langle 1 \\rangle},a^{\\langle 2 \\rangle}, ..., a^{ \\langle T_x \\rangle}]$ de la LSTM bidirectionnelle pr√©-attention, ainsi que l'√©tat cach√© pr√©c√©dent $s^{\u003ct-1\u003e}$ de la LSTM post-attention pour calculer le vecteur contexte $context^{\u003ct\u003e}$.\n","\n","    2. Donner $context^{\u003ct\u003e}$ √† la cellule LSTM post-attention.  \n","   - N'oubliez pas de passer l'√©tat cach√© pr√©c√©dent $s^{\\langle t-1\\rangle}$ et les √©tats de cellule $c^{\\langle t-1\\rangle}$ de cette LSTM.  \n","   * Cela produit le nouvel √©tat cach√© $s^{\u003ct\u003e}$ et le nouvel √©tat de cellule $c^{\u003ct\u003e}$.  \n","\n","   Exemple de code :\n","\n","        ```Python\n","        next_hidden_state, _ , next_cell_state =\n","            post_activation_LSTM_cell(inputs=..., initial_state=[prev_hidden_state, prev_cell_state])\n","        ```   \n","        Veuillez noter que cette couche est en fait la \"cellule LSTM post-attention\".  \n","Pour que la validation automatique fonctionne, merci de ne pas modifier le nom de cette variable globale.  \n","Cela sera corrig√© lors de la mise √† jour du validateur automatique.\n","\n","  3. Appliquez une couche dense avec activation softmax sur $s^{\u003ct\u003e}$ pour obtenir la sortie.\n","      Sample code:\n","      ```Python\n","      output = output_layer(inputs=...)\n","        ```\n","    4. Sauvegardez la sortie en l'ajoutant √† la liste des sorties.\n","\n","3. Cr√©ez votre instance de mod√®le Keras.  \n","   * Il doit avoir trois entr√©es :  \n","     * `X`, les entr√©es encod√©es en one-hot du mod√®le, de forme ($T_{x}, humanVocabSize)$  \n","     * $s^{\\langle 0 \\rangle}$, l'√©tat cach√© initial du LSTM post-attention  \n","     * $c^{\\langle 0 \\rangle}$, l'√©tat de cellule initial du LSTM post-attention  \n","   * La sortie est la liste des sorties.  \n","\n","    Exemple de code\n","    ```Python\n","    model = Model(inputs=[...,...,...], outputs=...)\n","    ```"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":87,"status":"ok","timestamp":1752440214332,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"qeKbeDOvh3Mo"},"outputs":[],"source":["# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n","# FONCTION NOT√âE : model\n","\n","def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n","    \"\"\"\n","    Arguments:\n","    Tx -- longueur de la s√©quence d'entr√©e\n","    Ty -- longueur de la s√©quence de sortie\n","    n_a -- taille de l'√©tat cach√© du Bi-LSTM\n","    n_s -- taille de l'√©tat cach√© du LSTM post-attention\n","    human_vocab_size -- taille du dictionnaire python \"human_vocab\"\n","    machine_vocab_size -- taille du dictionnaire python \"machine_vocab\"\n","\n","    Retourne:\n","    model -- instance du mod√®le Keras\n","    \"\"\"\n","\n","    # D√©finir les entr√©es de votre mod√®le avec une forme (Tx,)\n","    # D√©finir s0 (√©tat cach√© initial) et c0 (√©tat de cellule initial)\n","    # pour le d√©codeur LSTM avec une forme (n_s,)\n","    X = Input(shape=(Tx, human_vocab_size))\n","    s0 = Input(shape=(n_s,), name='s0')\n","    c0 = Input(shape=(n_s,), name='c0')\n","    s = s0\n","    c = c0\n","\n","    # Initialiser une liste vide pour les sorties\n","    outputs = []\n","\n","    ### D√âBUT DU CODE ###\n","\n","    # √âtape 1 : d√©finir votre Bi-LSTM pr√©-attention. (‚âà 1 ligne)\n","    a = Bidirectional(LSTM(units=32, return_sequences=True))(X)\n","\n","    # √âtape 2 : it√©rer pendant Ty √©tapes\n","    for t in range(Ty):\n","\n","        # √âtape 2.A : effectuer une √©tape du m√©canisme d'attention pour r√©cup√©rer le vecteur contexte √† l'√©tape t (‚âà 1 ligne)\n","        context = one_step_attention(a, s)\n","\n","        # √âtape 2.B : appliquer la cellule LSTM post-attention au vecteur \"context\".\n","        # N'oubliez pas de passer : initial_state = [√©tat cach√©, √©tat de cellule] (‚âà 1 ligne)\n","        s, _, c = post_activation_LSTM_cell(context, initial_state=[s,c])\n","\n","        # √âtape 2.C : appliquer la couche Dense √† la sortie de l'√©tat cach√© du LSTM post-attention (‚âà 1 ligne)\n","        out = output_layer(inputs=s)\n","\n","        # √âtape 2.D : ajouter \"out\" √† la liste \"outputs\" (‚âà 1 ligne)\n","        outputs.append(out)\n","\n","    # √âtape 3 : cr√©er une instance de mod√®le prenant trois entr√©es et retournant la liste des sorties. (‚âà 1 ligne)\n","    model = Model(inputs=[X,s0,c0], outputs=outputs)\n","\n","    ### FIN DU CODE ###\n","\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1752440221357,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"rQO8DyXfa19Q"},"outputs":[],"source":["from collections.abc import Sequence\n","# UNIT TEST\n","#from test_utils import *\n","\n","def modelf_test(target):\n","    m = 10\n","    Tx = 30\n","    n_a = 32\n","    n_s = 64\n","    len_human_vocab = 37\n","    len_machine_vocab = 11\n","\n","\n","    model = target(Tx, Ty, n_a, n_s, len_human_vocab, len_machine_vocab)\n","\n","    print(summary(model))\n","\n","\n","    expected_summary = [['InputLayer', [(None, 30, 37)], 0],\n","                         ['InputLayer', [(None, 64)], 0],\n","                         ['Bidirectional', (None, 30, 64), 17920],\n","                         ['RepeatVector', (None, 30, 64), 0, 30],\n","                         ['Concatenate', (None, 30, 128), 0],\n","                         ['Dense', (None, 30, 10), 1290, 'tanh'],\n","                         ['Dense', (None, 30, 1), 11, 'relu'],\n","                         ['Activation', (None, 30, 1), 0],\n","                         ['Dot', (None, 1, 64), 0],\n","                         ['InputLayer', [(None, 64)], 0],\n","                         ['LSTM',[(None, 64), (None, 64), (None, 64)], 33024,[(None, 1, 64), (None, 64), (None, 64)],'tanh'],\n","                         ['Dense', (None, 11), 715, 'softmax']]\n","\n","    assert len(model.outputs) == 10, f\"Wrong output shape. Expected 10 != {len(model.outputs)}\"\n","\n","    comparator(summary(model), expected_summary)\n","\n","\n","#modelf_test(modelf)"]},{"cell_type":"markdown","metadata":{"id":"9WG11VgUk-xp"},"source":[]},{"cell_type":"markdown","metadata":{"id":"--RX7hSsh3Mo"},"source":["Ex√©cutez la cellule suivante pour cr√©er votre mod√®le.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":186,"status":"ok","timestamp":1752440333945,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"2mInWdET5iss","outputId":"6b3612ef-4e91-4dad-9f1b-ccd76e838c5b"},"outputs":[{"data":{"text/plain":["(37, 11)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(human_vocab), len(machine_vocab)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1752440344391,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"psdd-Ac6h3Mp"},"outputs":[],"source":["model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"]},{"cell_type":"markdown","metadata":{"id":"nUJw7Xohh3Mp"},"source":["#### Note de d√©pannage  \n","* Si vous obtenez des erreurs r√©p√©t√©es apr√®s une premi√®re impl√©mentation incorrecte de la fonction \"model\", mais que vous pensez avoir corrig√© l‚Äôerreur, il est possible que vous continuiez √† voir des messages d‚Äôerreur lors de la construction du mod√®le.  \n","* Une solution consiste √† sauvegarder et red√©marrer votre noyau (ou arr√™ter puis red√©marrer votre notebook), puis relancer les cellules.\n"]},{"cell_type":"markdown","metadata":{"id":"VgeU_I9_h3Mp"},"source":["Obtenons un r√©sum√© du mod√®le pour v√©rifier s‚Äôil correspond √† la sortie attendue."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":734,"status":"ok","timestamp":1752440381006,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"tX0vaYmPh3Mq","outputId":"91ec29d5-0c92-4693-bb19-d48874cad388"},"outputs":[{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"functional\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u003cspan style=\"font-weight: bold\"\u003e Layer (type)        \u003c/span\u003e‚îÉ\u003cspan style=\"font-weight: bold\"\u003e Output Shape      \u003c/span\u003e‚îÉ\u003cspan style=\"font-weight: bold\"\u003e    Param # \u003c/span\u003e‚îÉ\u003cspan style=\"font-weight: bold\"\u003e Connected to      \u003c/span\u003e‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer         ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e37\u003c/span\u003e)    ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ -                 ‚îÇ\n","‚îÇ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ s0 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)        ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ -                 ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ bidirectional       ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)    ‚îÇ     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e17,920\u003c/span\u003e ‚îÇ input_layer[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e] ‚îÇ\n","‚îÇ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBidirectional\u003c/span\u003e)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ repeat_vector       ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)    ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ s0[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],         ‚îÇ\n","‚îÇ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eRepeatVector\u003c/span\u003e)      ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]        ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ concatenate         ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)   ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConcatenate\u003c/span\u003e)       ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)       ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e10\u003c/span\u003e)    ‚îÇ      \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1,290\u003c/span\u003e ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e] ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e)     ‚îÇ         \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e11\u003c/span\u003e ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]       ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ attention_weights   ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e)     ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eActivation\u003c/span\u003e)        ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]     ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dot (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDot\u003c/span\u003e)           ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)     ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]‚Ä¶ ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ c0 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)        ‚îÇ          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e ‚îÇ -                 ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ lstm (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eLSTM\u003c/span\u003e)         ‚îÇ [(\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e),      ‚îÇ     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e33,024\u003c/span\u003e ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e),       ‚îÇ            ‚îÇ s0[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],         ‚îÇ\n","‚îÇ                     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)]       ‚îÇ            ‚îÇ c0[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],         ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e]        ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)     ‚îÇ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e11\u003c/span\u003e)        ‚îÇ        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e715\u003c/span\u003e ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e8\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]        ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","\u003c/pre\u003e\n"],"text/plain":["‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)    ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n","‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ s0 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ bidirectional       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ     \u001b[38;5;34m17,920\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n","‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ repeat_vector       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         ‚îÇ\n","‚îÇ (\u001b[38;5;33mRepeatVector\u001b[0m)      ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ concatenate         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ (\u001b[38;5;33mConcatenate\u001b[0m)       ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m1\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m2\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m3\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m4\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m5\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m6\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m7\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m8\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ repeat_vector[\u001b[38;5;34m9\u001b[0m]‚Ä¶ ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10\u001b[0m)    ‚îÇ      \u001b[38;5;34m1,290\u001b[0m ‚îÇ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ concatenate[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     ‚îÇ         \u001b[38;5;34m11\u001b[0m ‚îÇ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]       ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ attention_weights   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ (\u001b[38;5;33mActivation\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dense_1[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dot (\u001b[38;5;33mDot\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ attention_weight‚Ä¶ ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ c0 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ lstm (\u001b[38;5;33mLSTM\u001b[0m)         ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      ‚îÇ     \u001b[38;5;34m33,024\u001b[0m ‚îÇ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       ‚îÇ            ‚îÇ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         ‚îÇ\n","‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       ‚îÇ            ‚îÇ c0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m2\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dot[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m2\u001b[0m]        ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        ‚îÇ        \u001b[38;5;34m715\u001b[0m ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m],       ‚îÇ\n","‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e52,960\u003c/span\u003e (206.88 KB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e52,960\u003c/span\u003e (206.88 KB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e (0.00 B)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"uiqCePt5h3Mr"},"source":["**Sortie attendue** :\n","\n","Voici le r√©sum√© que vous devriez voir :\n","\n","\u003ctable\u003e\n","    \u003ctr\u003e\n","        \u003ctd\u003e\n","            **Total params:**\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         52,960\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","        \u003ctr\u003e\n","        \u003ctd\u003e\n","            **Trainable params:**\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         52,960\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","            \u003ctr\u003e\n","        \u003ctd\u003e\n","            **Non-trainable params:**\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         0\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","                    \u003ctr\u003e\n","        \u003ctd\u003e\n","            **bidirectional_1's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 30, 64)  \n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","        \u003ctd\u003e\n","            **repeat_vector_1's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 30, 64)\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","                \u003ctr\u003e\n","        \u003ctd\u003e\n","            **concatenate_1's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 30, 128)\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","            \u003ctr\u003e\n","        \u003ctd\u003e\n","            **attention_weights's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 30, 1)  \n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","        \u003ctr\u003e\n","        \u003ctd\u003e\n","            **dot_1's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 1, 64)\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","           \u003ctr\u003e\n","        \u003ctd\u003e\n","            **dense_3's output shape **\n","        \u003c/td\u003e\n","        \u003ctd\u003e\n","         (None, 11)\n","        \u003c/td\u003e\n","    \u003c/tr\u003e\n","\u003c/table\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"8u3D9Odhh3Ms"},"source":["\u003ca name='ex-3'\u003e\u003c/a\u003e\n","### Exercice 3 - Compiler le mod√®le\n","\n","* Apr√®s avoir cr√©√© votre mod√®le avec Keras, vous devez le compiler et d√©finir la fonction de perte, l'optimiseur et les m√©triques que vous souhaitez utiliser.\n","    * Fonction de perte : 'categorical_crossentropy'.\n","    * Optimiseur : [Adam](https://keras.io/optimizers/#adam)  \n","  - taux d'apprentissage = 0.005  \n","  - $\\beta_1 = 0.9$  \n","  - $\\beta_2 = 0.999$  \n","  - decay = 0.01  \n","    * m√©trique : 'accuracy'\n","    \n","Exemple de code :\n","```Python\n","optimizer = Adam(lr=..., beta_1=..., beta_2=..., decay=...)\n","model.compile(optimizer=..., loss=..., metrics=[...])\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1752440387153,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"sBFRJ49rh3Ms"},"outputs":[],"source":["### DEBUT DU CODE ### (‚âà2 lines)\n","opt = Adam(learning_rate=0.005, beta_1=0.9 , beta_2=0.999)\n","model.compile(loss ='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'] * Ty)\n","### FIN DU CODE ###"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1752440392139,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"arLqEtzLa19R","outputId":"41674a8e-3651-4684-c06b-df4d7506a0d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92mTous les tests sont pass√©s !\n"]}],"source":["# TESTS UNITAIRES\n","assert opt.learning_rate == 0.005, \"R√©glez le param√®tre lr √† 0.005\"\n","assert opt.beta_1 == 0.9, \"R√©glez le param√®tre beta_1 √† 0.9\"\n","assert opt.beta_2 == 0.999, \"R√©glez le param√®tre beta_2 √† 0.999\"\n","# assert opt.decay == 0.01, \"R√©glez le param√®tre decay √† 0.01\" # V√©rification supprim√©e car d√©pr√©ci√©e\n","assert model.loss == \"categorical_crossentropy\", \"Mauvaise fonction de perte. Utilisez 'categorical_crossentropy'\"\n","assert model.optimizer == opt, \"Utilisez l'optimiseur que vous avez instanci√©\"\n","# assert model.compiled_metrics._user_metrics[0] == 'accuracy', \"R√©glez les m√©triques √† ['accuracy']\"\n","\n","print(\"\\033[92mTous les tests sont pass√©s !\")\n"]},{"cell_type":"markdown","metadata":{"id":"Qz71nM3oh3Ms"},"source":["#### D√©finir les entr√©es et sorties, puis entra√Æner le mod√®le\n","\n","La derni√®re √©tape consiste √† d√©finir toutes vos entr√©es et sorties pour entra√Æner le mod√®le :\n","- Vous disposez de l'entr√©e `Xoh` de forme $(m = 10000, T_x = 30, human\\_vocab=37)$ contenant les exemples d'entra√Ænement.\n","- Vous devez cr√©er `s0` et `c0` pour initialiser votre `post_attention_LSTM_cell` avec des z√©ros.\n","- Pour le mod√®le `model()` que vous avez cod√©, vous avez besoin que les \"outputs\" soient une liste de 10 √©l√©ments de forme $(m, T_y)$.\n","    - La liste `outputs[i][0], ..., outputs[i][Ty]` repr√©sente les vraies √©tiquettes (caract√®res) correspondant au $i^{√®me}$ exemple d'entra√Ænement (`Xoh[i]`).\n","    - `outputs[i][j]` est la vraie √©tiquette du $j^{√®me}$ caract√®re dans le $i^{√®me}$ exemple d'entra√Ænement.\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":55,"status":"ok","timestamp":1752440398370,"user":{"displayName":"Togo Datalab","userId":"00680866196184086567"},"user_tz":0},"id":"USFiNKYhh3Mt"},"outputs":[],"source":["s0 = np.zeros((m, n_s))\n","c0 = np.zeros((m, n_s))\n","outputs = list(Yoh.swapaxes(0,1))"]},{"cell_type":"markdown","metadata":{"id":"FVkITGi3h3Mt"},"source":["Entra√Ænons maintenant le mod√®le en lan√ßant une √©poque d'entra√Ænement.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPuwY45bh3Mt","outputId":"abb36790-e087-410a-8b43-975b8cd42a80"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - dense_2_accuracy: 0.2309 - dense_2_accuracy_1: 0.4645 - dense_2_accuracy_2: 0.1789 - dense_2_accuracy_3: 0.0685 - dense_2_accuracy_4: 0.8557 - dense_2_accuracy_5: 0.1017 - dense_2_accuracy_6: 0.0286 - dense_2_accuracy_7: 0.8551 - dense_2_accuracy_8: 0.1368 - dense_2_accuracy_9: 0.0673 - dense_2_loss: 2.6830 - loss: 19.7093\n","Epoch 2/5\n","\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - dense_2_accuracy: 0.9657 - dense_2_accuracy_1: 0.9662 - dense_2_accuracy_2: 0.4922 - dense_2_accuracy_3: 0.2526 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9362 - dense_2_accuracy_6: 0.4061 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.5358 - dense_2_accuracy_9: 0.2334 - dense_2_loss: 2.0955 - loss: 8.4523\n","Epoch 3/5\n","\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - dense_2_accuracy: 0.9796 - dense_2_accuracy_1: 0.9804 - dense_2_accuracy_2: 0.6389 - dense_2_accuracy_3: 0.4674 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9637 - dense_2_accuracy_6: 0.6063 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.6253 - dense_2_accuracy_9: 0.3103 - dense_2_loss: 1.8393 - loss: 6.4680\n","Epoch 4/5\n","\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - dense_2_accuracy: 0.9840 - dense_2_accuracy_1: 0.9828 - dense_2_accuracy_2: 0.7859 - dense_2_accuracy_3: 0.7242 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9710 - dense_2_accuracy_6: 0.7584 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.6839 - dense_2_accuracy_9: 0.4181 - dense_2_loss: 1.5610 - loss: 4.5987\n","Epoch 5/5\n","\u001b[1m 61/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - dense_2_accuracy: 0.9871 - dense_2_accuracy_1: 0.9851 - dense_2_accuracy_2: 0.8400 - dense_2_accuracy_3: 0.8504 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9750 - dense_2_accuracy_6: 0.8218 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.7356 - dense_2_accuracy_9: 0.5918 - dense_2_loss: 1.0845 - loss: 3.2650"]}],"source":["model.fit([Xoh, s0, c0], outputs, epochs=5, batch_size=100)"]},{"cell_type":"markdown","metadata":{"id":"SUikskCoh3Mt"},"source":["Pendant l'entra√Ænement, vous pouvez voir la perte ainsi que la pr√©cision pour chacune des 10 positions de la sortie. Le tableau ci-dessous donne un exemple de ce que les pr√©cisions pourraient √™tre si le batch contenait 2 exemples :\n","\n","\u003cimg src=\"https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQFp5Dn_qd6LpYqVJJhAgfGHh88O8ATGZylV-61NRP6OW88kTqj\" style=\"width:700;height:200px;\"\u003e \u003cbr\u003e\n","\u003ccaption\u003e\u003ccenter\u003ePar exemple, `dense_2_acc_8: 0.89` signifie que vous pr√©disez correctement le 7√®me caract√®re de la sortie 89% du temps sur le batch de donn√©es courant.\u003c/center\u003e\u003c/caption\u003e\n","\n","Nous avons entra√Æn√© ce mod√®le plus longtemps et sauvegard√© les poids. Ex√©cutez la cellule suivante pour charger nos poids. (En entra√Ænant un mod√®le plusieurs minutes, vous devriez obtenir une pr√©cision similaire, mais charger notre mod√®le vous fera gagner du temps.)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKVFnGZDmoTo"},"outputs":[],"source":["model.save('model.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooiZCOx0h3Mu"},"outputs":[],"source":["model.load_weights('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rQ8sd_cuh3Mv"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","source: 3 May 1979\n","output: 1999-05-03 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","source: 5 April 09\n","output: 2009-04-05 \n","\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-25-2649609632.py:12: DeprecationWarning: Conversion of an array with ndim \u003e 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  output = [inv_machine_vocab[int(i)] for i in prediction]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","source: 21th of August 2016\n","output: 2016-07-22 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","source: Tue 10 Jul 2007\n","output: 2007-07-00 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","source: Saturday May 9 2018\n","output: 2018-05-07 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","source: March 3 2001\n","output: 2011-03-03 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","source: March 3rd 2001\n","output: 2011-03-03 \n","\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","source: 1 March 2001\n","output: 2011-03-11 \n","\n"]}],"source":["EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n","s00 = np.zeros((1, n_s))\n","c00 = np.zeros((1, n_s))\n","for example in EXAMPLES:\n","    source = string_to_int(example, Tx, human_vocab)\n","    #print(source)\n","    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n","    source = np.swapaxes(source, 0, 1)\n","    source = np.expand_dims(source, axis=0)\n","    prediction = model.predict([source, s00, c00])\n","    prediction = np.argmax(prediction, axis = -1)\n","    output = [inv_machine_vocab[int(i)] for i in prediction]\n","    print(\"source:\", example)\n","    print(\"output:\", ''.join(output),\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"vjdEQiIDh3Mv"},"source":["Vous pouvez √©galement modifier ces exemples pour tester avec vos propres donn√©es. La partie suivante vous permettra de mieux comprendre ce que fait le m√©canisme d‚Äôattention ‚Äî c‚Äôest-√†-dire, quelle partie de l‚Äôentr√©e le r√©seau regarde lorsqu‚Äôil g√©n√®re un caract√®re de sortie particulier.\n"]},{"cell_type":"markdown","metadata":{"id":"1XIxtN4xh3Mv"},"source":["\u003ca name='3'\u003e\u003c/a\u003e\n","## 3 - Visualisation de l'Attention (Optionnel / Non not√©)\n","\n","Puisque le probl√®me a une longueur de sortie fixe de 10, il est aussi possible de r√©aliser cette t√¢che en utilisant 10 unit√©s softmax diff√©rentes pour g√©n√©rer les 10 caract√®res de la sortie. Mais un avantage du mod√®le d‚Äôattention est que chaque partie de la sortie (comme le mois) sait qu‚Äôelle doit d√©pendre seulement d‚Äôune petite partie de l‚Äôentr√©e (les caract√®res dans l‚Äôentr√©e donnant le mois). On peut visualiser quelle partie de l‚Äôentr√©e chaque partie de la sortie regarde.\n","\n","Consid√©rons la t√¢che de traduire ¬´ Saturday 9 May 2018 ¬ª en ¬´ 2018-05-09 ¬ª. Si on visualise les $\\alpha^{\\langle t, t' \\rangle}$ calcul√©s, on obtient ceci :\n","\n","\u003cimg src=\"https://wiki.hacksmeta.com/static/images/ML/DL/attention/date_attention.png\" style=\"width:600;height:300px;\"\u003e \u003cbr\u003e\n","\u003ccaption\u003e\u003ccenter\u003e **Figure 8** : Carte compl√®te d‚Äôattention\u003c/center\u003e\u003c/caption\u003e\n","\n","Remarquez comment la sortie ignore la partie ¬´ Saturday ¬ª de l‚Äôentr√©e. Aucun des pas de temps en sortie ne pr√™te beaucoup d‚Äôattention √† cette partie de l‚Äôentr√©e. On voit aussi que le 9 a √©t√© traduit en 09 et que May a √©t√© correctement traduit en 05, la sortie pr√™tant attention aux parties de l‚Äôentr√©e n√©cessaires pour faire la traduction. L‚Äôann√©e n√©cessite surtout que le mod√®le pr√™te attention au ¬´ 18 ¬ª dans l‚Äôentr√©e afin de g√©n√©rer ¬´ 2018 ¬ª.\n"]},{"cell_type":"markdown","metadata":{"id":"FrP893IFh3Mv"},"source":["\u003ca name='3-1'\u003e\u003c/a\u003e\n","### 3.1 - R√©cup√©ration des poids d‚Äôattention depuis le r√©seau\n","\n","Voyons maintenant comment visualiser les valeurs d‚Äôattention dans votre r√©seau. Nous allons faire passer un exemple √† travers le r√©seau, puis visualiser les valeurs de $\\alpha^{\\langle t, t' \\rangle}$.\n","\n","Pour savoir o√π se trouvent les valeurs d‚Äôattention, commen√ßons par afficher un r√©sum√© du mod√®le.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfiLrfKIh3Mv"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"zbcprBCPh3Mv"},"source":["Parcourez la sortie de `model.summary()` ci-dessus. Vous pouvez voir que la couche nomm√©e `attention_weights` produit les `alphas` de forme (m, 30, 1) avant que `dot_2` ne calcule le vecteur contexte pour chaque pas de temps $t = 0, \\ldots, T_y-1$. Allons r√©cup√©rer les poids d‚Äôattention de cette couche.\n","\n","La fonction `attention_map()` extrait les valeurs d‚Äôattention de votre mod√®le et les affiche graphiquement.\n","\n","**Note** : Nous savons que vous pourriez rencontrer une erreur en ex√©cutant la cellule ci-dessous malgr√© une impl√©mentation correcte de l‚ÄôExercice 2 - `modelf` ci-dessus. Si vous avez cette erreur, merci de la signaler sur ce [Topic](https://discourse.deeplearning.ai/t/error-in-optional-ungraded-part-of-neural-machine-translation-w3a1/1096) sur [Discourse](https://discourse.deeplearning.ai), cela nous aidera √† am√©liorer notre contenu.\n","\n","Si vous n‚Äô√™tes pas encore inscrit dans notre communaut√© Discourse, vous pouvez le faire en cliquant sur ce lien : http://bit.ly/dls-discourse\n","\n","Et ne vous inqui√©tez pas pour l‚Äôerreur, elle n‚Äôimpactera pas la notation de ce devoir.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQPA084la19T"},"outputs":[],"source":["attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tue 10 Jul 2007\", num = 7, n_s = 64);"]},{"cell_type":"markdown","metadata":{"id":"pQ3qbIjqh3Mx"},"source":["Sur le graphique g√©n√©r√©, vous pouvez observer les valeurs des poids d‚Äôattention pour chaque caract√®re de la sortie pr√©dite. Examinez ce graphique et v√©rifiez que les endroits o√π le r√©seau porte son attention vous semblent coh√©rents.\n","\n","Dans l‚Äôapplication de traduction de dates, vous constaterez que la majorit√© du temps, l‚Äôattention aide √† pr√©dire l‚Äôann√©e, et n‚Äôa pas autant d‚Äôimpact pour pr√©dire le jour ou le mois.\n"]},{"cell_type":"markdown","metadata":{"id":"IkpGu1Jkh3Mx"},"source":["### F√©licitations !\n","\n","Vous √™tes arriv√© √† la fin de ce devoir.\n","\n","#### Voici ce que vous devez retenir\n","\n","- Les mod√®les de traduction automatique peuvent √™tre utilis√©s pour transformer une s√©quence en une autre. Ils sont utiles non seulement pour traduire des langues humaines (comme du fran√ßais vers l‚Äôanglais) mais aussi pour des t√¢ches comme la traduction de formats de dates.\n","- Un m√©canisme d‚Äôattention permet √† un r√©seau de se concentrer sur les parties les plus pertinentes de l‚Äôentr√©e lors de la production d‚Äôune partie sp√©cifique de la sortie.\n","- Un r√©seau utilisant un m√©canisme d‚Äôattention peut traduire des entr√©es de longueur $T_x$ en sorties de longueur $T_y$, o√π $T_x$ et $T_y$ peuvent √™tre diff√©rents.\n","- Vous pouvez visualiser les poids d‚Äôattention $\\alpha^{\\langle t,t' \\rangle}$ pour voir o√π le r√©seau porte son attention lors de la g√©n√©ration de chaque sortie.\n"]},{"cell_type":"markdown","metadata":{"id":"ZaKA2u4uh3My"},"source":["F√©licitations pour avoir termin√© ce devoir ! Vous √™tes d√©sormais capable d‚Äôimpl√©menter un mod√®le d‚Äôattention et de l‚Äôutiliser pour apprendre des correspondances complexes d‚Äôune s√©quence √† une autre."]}],"metadata":{"colab":{"name":"","version":""},"coursera":{"schema_names":["DLSC5W3-1A"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}