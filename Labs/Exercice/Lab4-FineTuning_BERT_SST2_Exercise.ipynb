{"cells":[{"cell_type":"markdown","source":["> ðŸ“Œ **Avant de commencer :**\n",">\n","> [![Ouvrir dans Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1NIw1voN4xTsyJoowhIaeLD96nC3WngFf?usp=sharing)\n",">\n","> ðŸ” *Veuillez faire une copie dans votre Google Drive (`Fichier > Enregistrer une copie dans Drive`) avant toute modification.*\n"],"metadata":{"id":"Q0r8DviX22nQ"},"id":"Q0r8DviX22nQ"},{"cell_type":"markdown","id":"27c99b31","metadata":{"id":"27c99b31"},"source":["# ðŸ”¬ Exercise: Fine-Tuning BERT on SST-2 for Sentiment Analysis\n","Fill in the missing sections marked with `# TODO` to complete each step."]},{"cell_type":"markdown","id":"2d0d2dbe","metadata":{"id":"2d0d2dbe"},"source":["## 1. Setup\n","Install libraries and import modules."]},{"cell_type":"code","source":["! pip install torch transformers datasets evaluate scikit-learn tensorflow faker tqdm babel matplotlib\n","! pip install tf-keras\n","#!pip install --upgrade datasets aiohttp --quiet\n","! pip install --upgrade datasets fsspec\n"],"metadata":{"id":"E7iXG4IV53Z9"},"id":"E7iXG4IV53Z9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f49df5eb","metadata":{"id":"f49df5eb"},"outputs":[],"source":["!pip install transformers datasets evaluate scikit-learn --quiet\n","\n","# TODO: Import the following:\n","# torch\n","# BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments from transformers\n","# load_dataset from datasets\n","# numpy as np\n","# evaluate\n","# classification_report from sklearn.metrics"]},{"cell_type":"markdown","id":"2e8ec388","metadata":{"id":"2e8ec388"},"source":["## 2. Load SST-2 Dataset\n","Use the GLUE 'sst2' configuration."]},{"cell_type":"code","execution_count":null,"id":"e31d57c3","metadata":{"id":"e31d57c3"},"outputs":[],"source":["# TODO: Load the SST-2 dataset\n","#dataset =\n","print(dataset['train'][0])"]},{"cell_type":"markdown","id":"21ca00df","metadata":{"id":"21ca00df"},"source":["## 3. Preprocessing\n","Tokenize sentences with `max_length=128`, `truncation=True`, `padding='max_length'`."]},{"cell_type":"code","execution_count":null,"id":"4cd7a38e","metadata":{"id":"4cd7a38e"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def tokenize_function(example):\n","    # TODO: Tokenize the 'sentence' field\n","    return {}\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"id":"aaa98b07","metadata":{"id":"aaa98b07"},"outputs":[],"source":["# TODO: Set format to PyTorch tensors for ['input_ids','attention_mask','label']\n","# Hint: tokenized_datasets.set_format(...)"]},{"cell_type":"markdown","id":"19c5ab58","metadata":{"id":"19c5ab58"},"source":["## 4. Model Initialization\n","Load BERT for sequence classification with 2 labels."]},{"cell_type":"code","execution_count":null,"id":"6b3f4e1f","metadata":{"id":"6b3f4e1f"},"outputs":[],"source":["# TODO: Initialize model\n","model ="]},{"cell_type":"markdown","id":"4379a79a","metadata":{"id":"4379a79a"},"source":["## 5. Training Arguments\n","Configure `TrainingArguments`."]},{"cell_type":"code","execution_count":null,"id":"7c8af301","metadata":{"id":"7c8af301"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results_sst2',\n","    evaluation_strategy='epoch',\n","    save_strategy='epoch',\n","    logging_dir='./logs_sst2',\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='accuracy'\n",")"]},{"cell_type":"markdown","id":"16172a00","metadata":{"id":"16172a00"},"source":["## 6. Metrics\n","Define `compute_metrics` using accuracy."]},{"cell_type":"code","execution_count":null,"id":"26f41b80","metadata":{"id":"26f41b80"},"outputs":[],"source":["accuracy = evaluate.load('accuracy')\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    # TODO: Compute predictions and return accuracy\n","    return {}"]},{"cell_type":"markdown","id":"3d45f1b3","metadata":{"id":"3d45f1b3"},"source":["## 7. Training\n","Initialize `Trainer` and call `.train()`."]},{"cell_type":"code","execution_count":null,"id":"75b144fa","metadata":{"id":"75b144fa"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets['train'].shuffle(seed=42).select(range(5000)),\n","    eval_dataset=tokenized_datasets['validation'].select(range(1000)),\n","    compute_metrics=compute_metrics,\n",")\n","trainer.train()"]},{"cell_type":"markdown","id":"eb6bda74","metadata":{"id":"eb6bda74"},"source":["## 8. Evaluation\n","Generate predictions and print a classification report."]},{"cell_type":"code","execution_count":null,"id":"4e0a2126","metadata":{"id":"4e0a2126"},"outputs":[],"source":["# TODO: Use trainer.predict on validation set\n","# and print classification_report\n"]},{"cell_type":"markdown","id":"f3a1be76","metadata":{"id":"f3a1be76"},"source":["## 9. Save Model\n","Save model and tokenizer."]},{"cell_type":"code","execution_count":null,"id":"5bd6ca04","metadata":{"id":"5bd6ca04"},"outputs":[],"source":["# TODO: Save to './finetuned-bert-sst2-exercise'\n","model.save_pretrained('')\n","tokenizer.save_pretrained('')"]},{"cell_type":"markdown","id":"433bfe30","metadata":{"id":"433bfe30"},"source":["## 10. Inference\n","Write `predict_sentiment` to return 'positive' or 'negative'."]},{"cell_type":"code","execution_count":null,"id":"094d2cab","metadata":{"id":"094d2cab"},"outputs":[],"source":["def predict_sentiment(text):\n","    # TODO: Tokenize and run model\n","    return\n","\n","print(predict_sentiment('An absolutely wonderful film.'))"]},{"cell_type":"markdown","id":"98bed298","metadata":{"id":"98bed298"},"source":["## Conclusion\n","Complete all TODOs to finish the fine-tuning exercise. Good luck!"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}