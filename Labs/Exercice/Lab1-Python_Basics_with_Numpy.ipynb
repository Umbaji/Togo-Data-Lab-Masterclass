{"cells":[{"cell_type":"markdown","source":["> üìå **Avant de commencer :**\n",">\n","> [![Ouvrir dans Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1OEabE8ssnO8Pg60nFFaF_GT5r5UWr4m-?usp=sharing)\n",">\n","> üîÅ *Veuillez faire une copie dans votre Google Drive (`Fichier > Enregistrer une copie dans Drive`) avant toute modification.*\n"],"metadata":{"id":"B_oBbiV5_dP0"}},{"cell_type":"markdown","metadata":{"id":"SAcFQG52_XSw"},"source":["# üêç Bases de Python avec Numpy (exercice facultatif)\n","\n","Bienvenue dans votre premier exercice. Cet exercice vous offre une br√®ve introduction √† Python.  \n","M√™me si vous avez d√©j√† utilis√© Python, cela vous aidera √† vous familiariser avec les fonctions dont nous aurons besoin.\n","\n","---\n","\n","## üìå Instructions :\n","- Vous utiliserez **Python 3**.\n","- **√âvitez** d‚Äôutiliser des boucles `for` ou `while`, sauf indication contraire.\n","- Apr√®s avoir cod√© votre fonction, **ex√©cutez la cellule juste en dessous** pour v√©rifier si votre r√©sultat est correct.\n","\n","---\n","\n","## üéØ √Ä l‚Äôissue de cet exercice, vous serez capable de :\n","- Utiliser des **notebooks iPython**  \n","- Utiliser les **fonctions de `numpy`** et effectuer des op√©rations sur des **matrices/vecteurs numpy**  \n","- Comprendre le concept de **broadcasting**  \n","- **Vectoriser du code**\n","\n","---\n","\n","üöÄ **C‚Äôest parti !**\n"]},{"cell_type":"markdown","metadata":{"id":"cJ1N6d8G_XSz"},"source":["## üìö Table des mati√®res\n","\n","- [√Ä propos des notebooks iPython](#0)\n","    - [Exercice 1](#ex-1)\n","\n","- [1 - Construire des fonctions de base avec numpy](#1)\n","    - [1.1 - Fonction sigmo√Øde, `np.exp()`](#1-1)\n","        - [Exercice 2 - basic_sigmoid](#ex-2)\n","        - [Exercice 3 - sigmoid](#ex-3)\n","    - [1.2 - D√©riv√©e de la fonction sigmo√Øde](#1-2)\n","        - [Exercice 4 - sigmoid_derivative](#ex-4)\n","    - [1.3 - Remodelage des tableaux](#1-3)\n","        - [Exercice 5 - image2vector](#ex-5)\n","    - [1.4 - Normalisation des lignes](#1-4)\n","        - [Exercice 6 - normalize_rows](#ex-6)\n","        - [Exercice 7 - softmax](#ex-7)\n","\n","- [2 - Vectorisation](#2)\n","    - [2.1 - Impl√©mentation des fonctions de perte L1 et L2](#2-1)\n","        - [Exercice 8 - L1](#ex-8)\n","        - [Exercice 9 - L2](#ex-9)\n"]},{"cell_type":"markdown","source":["## Executez cette cellule pour les fonctions utiles:\n","## Ne modifiez rien ici."],"metadata":{"id":"w6AhHexEEOPv"}},{"cell_type":"code","source":["import numpy as np\n","\n","def test(test_cases, target):\n","    success = 0\n","    for test_case in test_cases:\n","        try:\n","            if test_case['name'] == \"datatype_check\":\n","                assert isinstance(target(*test_case['input']),\n","                                  test_case[\"expected\"])\n","                success += 1\n","            if test_case['name'] == \"equation_output_check\":\n","                assert np.allclose(test_case[\"expected\"],\n","                                   target(*test_case['input']))\n","                success += 1\n","            if test_case['name'] == \"shape_check\":\n","                assert test_case['expected'].shape == target(*test_case['input']).shape\n","                success += 1\n","        except:\n","            print(\"Error: \" + test_case['error'])\n","\n","    if success == len(test_cases):\n","        print(\"\\033[92m All tests passed.\")\n","    else:\n","        print('\\033[92m', success,\" Tests passed\")\n","        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n","        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n","\n","\n","\n","\n","def basic_sigmoid_test(target):\n","    x = 1\n","    expected_output = 0.7310585786300049\n","    test_cases = [\n","        {\n","            \"name\": \"datatype_check\",\n","            \"input\": [x],\n","            \"expected\": float,\n","            \"error\": \"Datatype mismatch.\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output.\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def sigmoid_test(target):\n","    x = np.array([1, 2, 3])\n","    expected_output = np.array([0.73105858,\n","                                0.88079708,\n","                                0.95257413])\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [x],\n","            \"expected\": np.ndarray,\n","            \"error\":\"Datatype mismatch.\"\n","        },\n","        {\n","            \"name\": \"shape_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong shape.\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output.\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","\n","\n","def sigmoid_derivative_test(target):\n","    x = np.array([1, 2, 3])\n","    expected_output = np.array([0.19661193,\n","                                0.10499359,\n","                                0.04517666])\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [x],\n","            \"expected\": np.ndarray,\n","            \"error\":\"The function should return a numpy array.\"\n","        },\n","        {\n","            \"name\": \"shape_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong shape.\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output.\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def image2vector_test(target):\n","    image = np.array([[[ 0.67826139,  0.29380381],\n","                      [ 0.90714982,  0.52835647],\n","                      [ 0.4215251 ,  0.45017551]],\n","\n","                     [[ 0.92814219,  0.96677647],\n","                      [ 0.85304703,  0.52351845],\n","                      [ 0.19981397,  0.27417313]],\n","\n","                     [[ 0.60659855,  0.00533165],\n","                      [ 0.10820313,  0.49978937],\n","                      [ 0.34144279,  0.94630077]]])\n","\n","    expected_output = np.array([[ 0.67826139],\n","                                [ 0.29380381],\n","                                [ 0.90714982],\n","                                [ 0.52835647],\n","                                [ 0.4215251 ],\n","                                [ 0.45017551],\n","                                [ 0.92814219],\n","                                [ 0.96677647],\n","                                [ 0.85304703],\n","                                [ 0.52351845],\n","                                [ 0.19981397],\n","                                [ 0.27417313],\n","                                [ 0.60659855],\n","                                [ 0.00533165],\n","                                [ 0.10820313],\n","                                [ 0.49978937],\n","                                [ 0.34144279],\n","                                [ 0.94630077]])\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [image],\n","            \"expected\": np.ndarray,\n","            \"error\":\"The function should return a numpy array.\"\n","        },\n","        {\n","            \"name\": \"shape_check\",\n","            \"input\": [image],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong shape\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [image],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def normalizeRows_test(target):\n","    x = np.array([[0, 3, 4],\n","                  [1, 6, 4]])\n","    expected_output = np.array([[ 0., 0.6, 0.8 ],\n","                                [ 0.13736056, 0.82416338, 0.54944226]])\n","\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [x],\n","            \"expected\": np.ndarray,\n","            \"error\":\"The function should return a numpy array.\"\n","        },\n","        {\n","            \"name\": \"shape_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong shape\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def softmax_test(target):\n","    x = np.array([[9, 2, 5, 0, 0],\n","                  [7, 5, 0, 0 ,0]])\n","    expected_output = np.array([[ 9.80897665e-01, 8.94462891e-04,\n","                                 1.79657674e-02, 1.21052389e-04,\n","                                 1.21052389e-04],\n","\n","                                [ 8.78679856e-01, 1.18916387e-01,\n","                                 8.01252314e-04, 8.01252314e-04,\n","                                 8.01252314e-04]])\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [x],\n","            \"expected\": np.ndarray,\n","            \"error\":\"The function should return a numpy array.\"\n","        },\n","        {\n","            \"name\": \"shape_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong shape\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [x],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def L1_test(target):\n","    yhat = np.array([.9, 0.2, 0.1, .4, .9])\n","    y = np.array([1, 0, 0, 1, 1])\n","    expected_output = 1.1\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [yhat, y],\n","            \"expected\": float,\n","            \"error\":\"The function should return a float.\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [yhat, y],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n","\n","def L2_test(target):\n","    yhat = np.array([.9, 0.2, 0.1, .4, .9])\n","    y = np.array([1, 0, 0, 1, 1])\n","    expected_output = 0.43\n","\n","    test_cases = [\n","        {\n","            \"name\":\"datatype_check\",\n","            \"input\": [yhat, y],\n","            \"expected\": float,\n","            \"error\":\"The function should return a float.\"\n","        },\n","        {\n","            \"name\": \"equation_output_check\",\n","            \"input\": [yhat, y],\n","            \"expected\": expected_output,\n","            \"error\": \"Wrong output\"\n","        }\n","    ]\n","\n","    test(test_cases, target)\n"],"metadata":{"id":"q6NuEt7sA62a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"ZG5H-FPUA6Ts"}},{"cell_type":"markdown","metadata":{"id":"zWg6WGyn_XS0"},"source":["<a name='0'></a>\n","## √Ä propos des notebooks iPython ##\n","\n","Les notebooks iPython sont des environnements de codage interactifs int√©gr√©s dans une page web.  \n","Vous utiliserez des notebooks iPython dans ce cours.\n","\n","Vous n'avez besoin d'√©crire du code **qu'entre les commentaires `# votre code ici`**.  \n","Apr√®s avoir √©crit votre code, vous pouvez ex√©cuter la cellule en appuyant sur **\"SHIFT\" + \"ENTR√âE\"**  \n","ou en cliquant sur **\"Ex√©cuter la cellule\"** (repr√©sent√© par une ic√¥ne en forme de ‚ñ∂Ô∏è) dans la barre sup√©rieure du notebook.\n","\n","Nous indiquerons souvent dans les commentaires **\"(‚âà X lignes de code)\"** pour vous donner une id√©e approximative  \n","de la quantit√© de code attendue. C‚Äôest simplement une estimation, donc ne vous inqui√©tez pas si votre code est plus long ou plus court.\n","\n","---\n","\n","<a name='ex-1'></a>\n","### üß™ Exercice 1\n","\n","Affectez la valeur `\"Hello World\"` √† la variable 'Test` dans la cellule ci-dessous pour afficher \"Hello World\",  \n","puis ex√©cutez les deux cellules suivantes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"53ecb05267db45908a4d1c3f727eeb1c","grade":false,"grade_id":"cell-edef848c738402d1","locked":false,"schema_version":3,"solution":true,"task":false},"id":"TEpZ_Uxo_XS0"},"outputs":[],"source":["# (‚âà 1 line of code)\n"," # Test = ...\n","# YOUR CODE STARTS HERE\n","\n","\n","# YOUR CODE ENDS HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u70FufYC_XS1"},"outputs":[],"source":["print (\"test: \" + Test)"]},{"cell_type":"markdown","metadata":{"id":"b0zl8h1X_XS1"},"source":["**Expected output**:\n","test: Hello World"]},{"cell_type":"markdown","metadata":{"id":"QWQvaA27_XS1"},"source":["<font color='red'>\n","<b>Ce qu‚Äôil faut retenir :</b>\n","\n","- Ex√©cutez vos cellules en utilisant **SHIFT+ENTR√âE** (ou **¬´ Ex√©cuter la cellule ¬ª**)  \n","- √âcrivez votre code uniquement dans les zones pr√©vues, en utilisant **Python 3**  \n","- Ne modifiez pas le code en dehors des zones pr√©vues  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"9q0ziR0F_XS1"},"source":["<a name='1'></a>\n","## 1 - Construire des fonctions de base avec numpy ##\n","\n","Numpy est la biblioth√®que principale pour le calcul scientifique en Python.  \n","Elle est maintenue par une large communaut√© (www.numpy.org).  \n","Dans cet exercice, vous apprendrez plusieurs fonctions cl√©s de numpy telles que `np.exp`, `np.log` et `np.reshape`.  \n","Vous devrez savoir utiliser ces fonctions pour les exercices futurs.\n","\n","<a name='1-1'></a>\n","### 1.1 - Fonction sigmo√Øde, `np.exp()` ###\n","\n","Avant d‚Äôutiliser `np.exp()`, vous utiliserez `math.exp()` pour impl√©menter la fonction sigmo√Øde.  \n","Vous verrez ensuite pourquoi `np.exp()` est pr√©f√©rable √† `math.exp()`.\n","\n","<a name='ex-2'></a>\n","### Exercice 2 - basic_sigmoid\n","\n","Construisez une fonction qui retourne la sigmo√Øde d‚Äôun nombre r√©el `x`.  \n","Utilisez `math.exp(x)` pour la fonction exponentielle.\n","\n","**Rappel :**  \n","$sigmoid(x) = \\frac{1}{1+e^{-x}}$ est parfois appel√©e fonction logistique.  \n","C‚Äôest une fonction non-lin√©aire utilis√©e non seulement en apprentissage automatique (r√©gression logistique),  \n","mais aussi en apprentissage profond.\n","\n","![Courbe logistique](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1920px-Logistic-curve.svg.png)\n","\n","Pour appeler une fonction appartenant √† un module sp√©cifique, vous pouvez utiliser la syntaxe `nom_module.fonction()`.  \n","Ex√©cutez le code ci-dessous pour voir un exemple avec `math.exp()`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"7cec1a2c77dcc9c6a59470e3daf70f45","grade":false,"grade_id":"cell-7f38ddeceef22374","locked":false,"schema_version":3,"solution":true,"task":false},"id":"Z3RrPaX3_XS2"},"outputs":[],"source":["import math\n","from public_tests import *\n","\n","# GRADED FUNCTION: basic_sigmoid\n","\n","def basic_sigmoid(x):\n","    \"\"\"\n","    Compute sigmoid of x.\n","\n","    Arguments:\n","    x -- A scalar\n","\n","    Return:\n","    s -- sigmoid(x)\n","    \"\"\"\n","    # (‚âà 1 line of code)\n","    # s =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return s"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"150772e06208b50e91305b4ecf1421d4","grade":true,"grade_id":"cell-6a7680d0a31b818e","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"6JV_tzPm_XS2"},"outputs":[],"source":["print(\"basic_sigmoid(1) = \" + str(basic_sigmoid(1)))\n","\n","basic_sigmoid_test(basic_sigmoid)"]},{"cell_type":"markdown","metadata":{"id":"pRJsVWVK_XS2"},"source":["En r√©alit√©, nous utilisons rarement la biblioth√®que math en apprentissage profond car les entr√©es des fonctions sont des nombres r√©els.\n","En deep learning, nous manipulons surtout des matrices et des vecteurs.\n","C‚Äôest pourquoi numpy est beaucoup plus utile.."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hD1BEGQt_XS2"},"outputs":[],"source":["### One reason why we use \"numpy\" instead of \"math\" in Deep Learning ###\n","\n","x = [1, 2, 3] # x becomes a python list object\n","basic_sigmoid(x) # you will see this give an error when you run it, because x is a vector."]},{"cell_type":"markdown","metadata":{"id":"MTpk3XH-_XS2"},"source":["In fact, if $ x = (x_1, x_2, ..., x_n)$ is a row vector then `np.exp(x)` will apply the exponential function to every element of x. The output will thus be: `np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMEpx1ip_XS2"},"outputs":[],"source":["import numpy as np\n","\n","# example of np.exp\n","t_x = np.array([1, 2, 3])\n","print(np.exp(t_x)) # result is (exp(1), exp(2), exp(3))"]},{"cell_type":"markdown","metadata":{"id":"z643hPkG_XS2"},"source":["Furthermore, if x is a vector, then a Python operation such as $s = x + 3$ or $s = \\frac{1}{x}$ will output s as a vector of the same size as x."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4Ze_TEJ_XS2"},"outputs":[],"source":["# example of vector operation\n","t_x = np.array([1, 2, 3])\n","print (t_x + 3)"]},{"cell_type":"markdown","metadata":{"id":"FZyfEUX5_XS2"},"source":["Chaque fois que vous avez besoin de plus d‚Äôinformations sur une fonction numpy, nous vous encourageons √† consulter  \n","[la documentation officielle](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html).\n","\n","Vous pouvez aussi cr√©er une nouvelle cellule dans le notebook et √©crire `np.exp?` (par exemple) pour acc√©der rapidement √† la documentation.\n","\n","<a name='ex-3'></a>\n","### Exercice 3 - sigmoid\n","\n","Impl√©mentez la fonction sigmo√Øde en utilisant numpy.\n","\n","**Instructions** :  \n","`x` peut maintenant √™tre un nombre r√©el, un vecteur ou une matrice.  \n","Les structures de donn√©es que nous utilisons dans numpy pour repr√©senter ces formes (vecteurs, matrices...) s‚Äôappellent des tableaux numpy (numpy arrays).  \n","Vous n‚Äôavez pas besoin d‚Äôen savoir plus pour le moment.\n","\n","$$\n","\\text{Pour } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n","    x_1  \\\\\n","    x_2  \\\\\n","    \\vdots  \\\\\n","    x_n  \\\\\n","\\end{pmatrix} = \\begin{pmatrix}\n","    \\frac{1}{1+e^{-x_1}}  \\\\\n","    \\frac{1}{1+e^{-x_2}}  \\\\\n","    \\vdots  \\\\\n","    \\frac{1}{1+e^{-x_n}}  \\\\\n","\\end{pmatrix} \\tag{1}\n","$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"fcab43fa930612b05f46fdd1421443db","grade":false,"grade_id":"cell-4c5ca880d9cf9642","locked":false,"schema_version":3,"solution":true,"task":false},"id":"1D14Z54N_XS2"},"outputs":[],"source":["# GRADED FUNCTION: sigmoid\n","\n","def sigmoid(x):\n","    \"\"\"\n","    Compute the sigmoid of x\n","\n","    Arguments:\n","    x -- A scalar or numpy array of any size\n","\n","    Return:\n","    s -- sigmoid(x)\n","    \"\"\"\n","\n","    # (‚âà 1 line of code)\n","    # s =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return s"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"7d6c9b80614b72a798e6df324bf20051","grade":true,"grade_id":"cell-215cfe583f712716","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"unS2KLMo_XS3"},"outputs":[],"source":["t_x = np.array([1, 2, 3])\n","print(\"sigmoid(t_x) = \" + str(sigmoid(t_x)))\n","\n","sigmoid_test(sigmoid)"]},{"cell_type":"markdown","metadata":{"id":"RwgqUmDX_XS3"},"source":["<a name='1-2'></a>\n","### 1.2 - Gradient de la sigmo√Øde\n","\n","Comme vous l‚Äôavez vu en cours, vous aurez besoin de calculer des gradients pour optimiser les fonctions de perte via la r√©tropropagation.  \n","Commen√ßons par coder votre premi√®re fonction de gradient.\n","\n","<a name='ex-4'></a>\n","### Exercice 4 - sigmoid_derivative\n","\n","Impl√©mentez la fonction `sigmoid_grad()` pour calculer le gradient de la fonction sigmo√Øde par rapport √† son entr√©e `x`. La formule est :\n","\n","$$\n","sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) \\times (1 - \\sigma(x)) \\tag{2}\n","$$\n","\n","Vous coderez souvent cette fonction en deux √©tapes :  \n","1. Affectez √† `s` la valeur de la sigmo√Øde appliqu√©e √† `x`. Votre fonction `sigmoid(x)` peut vous √™tre utile ici.  \n","2. Calculez le gradient : $\\sigma'(x) = s(1-s)$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"345fa4e729d4a65fc75c7b67b571b053","grade":false,"grade_id":"cell-3e66ce00e171b40b","locked":false,"schema_version":3,"solution":true,"task":false},"id":"Sdrmgtd6_XS3"},"outputs":[],"source":["# GRADED FUNCTION: sigmoid_derivative\n","\n","def sigmoid_derivative(x):\n","    \"\"\"\n","    Compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x.\n","    You can store the output of the sigmoid function into variables and then use it to calculate the gradient.\n","\n","    Arguments:\n","    x -- A scalar or numpy array\n","\n","    Return:\n","    ds -- Your computed gradient.\n","    \"\"\"\n","\n","    #(‚âà 2 lines of code)\n","    # s =\n","    # ds =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"db2f9ff9a137194ea17617bb758e1897","grade":true,"grade_id":"cell-1b027673871951a1","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"QSdSrWJq_XS3"},"outputs":[],"source":["t_x = np.array([1, 2, 3])\n","print (\"sigmoid_derivative(t_x) = \" + str(sigmoid_derivative(t_x)))\n","\n","sigmoid_derivative_test(sigmoid_derivative)"]},{"cell_type":"markdown","metadata":{"id":"m7_p4Tju_XS3"},"source":["<a name='1-3'></a>\n","### 1.3 - Remodelage des tableaux (reshaping) ###\n","\n","Deux fonctions numpy couramment utilis√©es en deep learning sont [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) et [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) :  \n","- `X.shape` sert √† obtenir la forme (dimensions) d‚Äôune matrice ou d‚Äôun vecteur `X`.  \n","- `X.reshape(...)` sert √† remodeler `X` dans une autre dimension.\n","\n","Par exemple, en informatique, une image est repr√©sent√©e par un tableau 3D de forme $(longueur, hauteur, profondeur = 3)$.  \n","Cependant, lorsqu‚Äôon lit une image comme entr√©e d‚Äôun algorithme, on la convertit en un vecteur de forme $(longueur \\times hauteur \\times 3, 1)$.  \n","Autrement dit, on ¬´ d√©roule ¬ª ou remodelle le tableau 3D en un vecteur 1D.\n","\n","![Illustration reshape](https://i-blog.csdnimg.cn/blog_migrate/7eac14f3dcf8d84f755c203f391db54d.png)\n","\n","<a name='ex-5'></a>\n","### Exercice 5 - image2vector\n","\n","Impl√©mentez `image2vector()` qui prend en entr√©e un tableau de forme `(longueur, hauteur, 3)`  \n","et retourne un vecteur de forme `(longueur * hauteur * 3, 1)`.\n","\n","Par exemple, si vous souhaitez remodeler un tableau `v` de forme `(a, b, c)` en un vecteur de forme `(a*b, c)`, vous pouvez faire :\n","\n","```python\n","v = v.reshape((v.shape[0] * v.shape[1], v.shape[2]))  # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"bdcbf18137f7cfa2d6ca62c4cf5c9c5d","grade":false,"grade_id":"cell-b68b7900fdd239cd","locked":false,"schema_version":3,"solution":true,"task":false},"id":"byjEnY5a_XS3"},"outputs":[],"source":["# GRADED FUNCTION:image2vector\n","\n","def image2vector(image):\n","    \"\"\"\n","    Argument:\n","    image -- a numpy array of shape (length, height, depth)\n","\n","    Returns:\n","    v -- a vector of shape (length*height*depth, 1)\n","    \"\"\"\n","\n","    # (‚âà 1 line of code)\n","    # v =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return v"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"339250a81053c3773a053c91cc46fb41","grade":true,"grade_id":"cell-3b78eb8b041424f7","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"B5tBc_Gb_XS3"},"outputs":[],"source":["# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n","t_image = np.array([[[ 0.67826139,  0.29380381],\n","                     [ 0.90714982,  0.52835647],\n","                     [ 0.4215251 ,  0.45017551]],\n","\n","                   [[ 0.92814219,  0.96677647],\n","                    [ 0.85304703,  0.52351845],\n","                    [ 0.19981397,  0.27417313]],\n","\n","                   [[ 0.60659855,  0.00533165],\n","                    [ 0.10820313,  0.49978937],\n","                    [ 0.34144279,  0.94630077]]])\n","\n","print (\"image2vector(image) = \" + str(image2vector(t_image)))\n","\n","image2vector_test(image2vector)\n"]},{"cell_type":"markdown","metadata":{"id":"Q5znuPTu_XS3"},"source":["<a name='1-4'></a>\n","### 1.4 - Normalisation des lignes\n","\n","Une autre technique courante en apprentissage automatique et apprentissage profond est de normaliser nos donn√©es.  \n","Cela conduit souvent √† de meilleures performances, car la descente de gradient converge plus rapidement apr√®s normalisation.  \n","Ici, par normalisation, on entend transformer \\( x \\) en \\( \\frac{x}{\\| x \\|} \\) (diviser chaque vecteur ligne de \\( x \\) par sa norme).\n","\n","Par exemple, si  \n","$$\n","x = \\begin{bmatrix}\n","        0 & 3 & 4 \\\\\n","        2 & 6 & 4 \\\\\n","\\end{bmatrix} \\tag{3}\n","$$  \n","alors  \n","$$\n","\\| x \\| = \\text{np.linalg.norm(x, axis=1, keepdims=True)} = \\begin{bmatrix}\n","    5 \\\\\n","    \\sqrt{56} \\\\\n","\\end{bmatrix} \\tag{4}\n","$$  \n","et  \n","$$\n","x\\_normalized = \\frac{x}{\\| x \\|} = \\begin{bmatrix}\n","    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n","    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n","\\end{bmatrix} \\tag{5}\n","$$\n","\n","Notez que vous pouvez diviser des matrices de tailles diff√©rentes, et cela fonctionne correctement : c‚Äôest ce qu‚Äôon appelle le **broadcasting**, que vous apprendrez dans la partie 5.\n","\n","Avec `keepdims=True`, le r√©sultat sera correctement diffus√© (broadcast√©) par rapport √† la matrice originale \\( x \\).\n","\n","`axis=1` signifie que la norme est calcul√©e ligne par ligne.  \n","Si vous souhaitez la norme colonne par colonne, il faudra mettre `axis=0`.\n","\n","`numpy.linalg.norm` poss√®de un autre param√®tre `ord` qui permet de sp√©cifier le type de normalisation √† effectuer  \n","(dans l‚Äôexercice ci-dessous, vous utiliserez la norme 2).  \n","Pour vous familiariser avec les diff√©rents types de normes, vous pouvez consulter la documentation :  \n","[numpy.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)\n","\n","<a name='ex-6'></a>\n","### Exercice 6 - normalize_rows\n","\n","Impl√©mentez la fonction `normalizeRows()` pour normaliser les lignes d‚Äôune matrice.  \n","Apr√®s application de cette fonction sur une matrice \\( x \\), chaque ligne de \\( x \\) doit √™tre un vecteur de norme 1 (c‚Äôest-√†-dire de longueur 1).\n","\n","**Remarque** :  \n","N‚Äôessayez pas d‚Äôutiliser `x /= x_norm`.  \n","Pour la division matricielle, numpy doit pouvoir faire du broadcasting de `x_norm`, ce qui n‚Äôest pas support√© par l‚Äôop√©rateur `/=`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"dc112a436b66b6526a5fbfe1e7822ba8","grade":false,"grade_id":"cell-5a030834cece94f4","locked":false,"schema_version":3,"solution":true,"task":false},"id":"WkxXwPUr_XS3"},"outputs":[],"source":["# GRADED FUNCTION: normalize_rows\n","\n","def normalize_rows(x):\n","    \"\"\"\n","    Implement a function that normalizes each row of the matrix x (to have unit length).\n","\n","    Argument:\n","    x -- A numpy matrix of shape (n, m)\n","\n","    Returns:\n","    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n","    \"\"\"\n","\n","    #(‚âà 2 lines of code)\n","    # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n","    # x_norm =\n","    # Divide x by its norm.\n","    # x =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"4c780d41666f3144b0d68804c2df2e21","grade":true,"grade_id":"cell-0910101c4de92095","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"q_4tx7bl_XS3"},"outputs":[],"source":["x = np.array([[0, 3, 4],\n","              [1, 6, 4]])\n","print(\"normalizeRows(x) = \" + str(normalize_rows(x)))\n","\n","normalizeRows_test(normalize_rows)"]},{"cell_type":"markdown","metadata":{"id":"PrS2QAxn_XS3"},"source":["**Remarque** :  \n","Dans la fonction `normalize_rows()`, vous pouvez essayer d'afficher les dimensions de `x_norm` et `x`, puis relancer l'√©valuation. Vous constaterez qu'ils ont des formes diff√©rentes. C'est normal, car `x_norm` calcule la norme de chaque ligne de `x`. Ainsi, `x_norm` a le m√™me nombre de lignes mais une seule colonne.  \n","\n","**Comment la division `x / x_norm` fonctionne-t-elle ?**  \n","Cela est possible gr√¢ce au **broadcasting** (diffusion), un m√©canisme de NumPy qui √©tend automatiquement les dimensions pour effectuer des op√©rations entre tableaux de formes compatibles. Nous expliquerons ce concept en d√©tail par la suite !"]},{"cell_type":"markdown","metadata":{"id":"SltAHSgy_XS3"},"source":["<a name='ex-7'></a>\n","### Exercice 7 - softmax\n","\n","Impl√©mentez une fonction softmax en utilisant numpy.  \n","Vous pouvez voir la fonction softmax comme une fonction de normalisation utilis√©e lorsque votre algorithme doit classer deux classes ou plus.  \n","Vous en apprendrez davantage sur softmax dans le deuxi√®me cours de cette sp√©cialisation.\n","\n","**Instructions** :  \n","- Pour$  x \\in \\mathbb{R}^{1 \\times n} $,\n","\n","\n"," $softmax(x) = softmax\\left(\\begin{bmatrix}\n","    x_1 & x_2 & \\dots & x_n\n","\\end{bmatrix}\\right)\n","= \\begin{bmatrix}\n","    \\frac{e^{x_1}}{\\sum_{j} e^{x_j}} & \\frac{e^{x_2}}{\\sum_{j} e^{x_j}} & \\dots & \\frac{e^{x_n}}{\\sum_{j} e^{x_j}}\n","\\end{bmatrix}\n","$\n","\n","- Pour une matrice  $x \\in \\mathbb{R}^{m \\times n} $, o√π $ x_{ij} $ d√©signe l‚Äô√©l√©ment de la $ i^{\\text{√®me}} $ ligne et de la $ j^{\\text{√®me}} $ colonne de $ x $, nous avons :\n","\n","\n","\\begin{align*}\n","softmax(x) &= softmax\\begin{bmatrix}\n","            x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n","            x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n","            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","            x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n","            \\end{bmatrix} \\\\ \\\\&=\n"," \\begin{bmatrix}\n","    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n","    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n","    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n","\\end{bmatrix} \\\\ \\\\ &= \\begin{pmatrix}\n","    softmax\\text{(first row of x)}  \\\\\n","    softmax\\text{(second row of x)} \\\\\n","    \\vdots  \\\\\n","    softmax\\text{(last row of x)} \\\\\n","\\end{pmatrix}\n","\\end{align*}\n"]},{"cell_type":"markdown","metadata":{"id":"0eY6nUoV_XS3"},"source":["**Notes :**  \n","Notez que plus tard dans le cours, vous verrez que ¬´‚ÄØm‚ÄØ¬ª sera utilis√© pour repr√©senter le ¬´‚ÄØnombre d‚Äôexemples d‚Äôentra√Ænement‚ÄØ¬ª,  \n","et que chaque exemple d‚Äôentra√Ænement sera dans sa propre colonne de la matrice.  \n","De plus, chaque caract√©ristique (feature) sera dans sa propre ligne (chaque ligne contient les donn√©es pour une m√™me caract√©ristique).  \n","\n","La fonction softmax devra alors √™tre appliqu√©e √† toutes les caract√©ristiques de chaque exemple d‚Äôentra√Ænement,  \n","donc softmax sera effectu√©e sur les colonnes (lorsque nous passerons √† cette repr√©sentation plus tard dans le cours).\n","\n","Cependant, dans cet exercice de codage,  \n","nous nous concentrons simplement sur la familiarisation avec Python,  \n","c‚Äôest pourquoi nous utilisons la notation math√©matique classique \\( m \\times n \\)  \n","o√π \\( m \\) est le nombre de lignes et \\( n \\) le nombre de colonnes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"5100054e6e6ea2c9a6343b43406cf909","grade":false,"grade_id":"cell-f41746c0a00bd2fc","locked":false,"schema_version":3,"solution":true,"task":false},"id":"iC52TAg5_XS3"},"outputs":[],"source":["# GRADED FUNCTION: softmax\n","\n","def softmax(x):\n","    \"\"\"Calculates the softmax for each row of the input x.\n","\n","    Your code should work for a row vector and also for matrices of shape (m,n).\n","\n","    Argument:\n","    x -- A numpy matrix of shape (m,n)\n","\n","    Returns:\n","    s -- A numpy matrix equal to the softmax of x, of shape (m,n)\n","    \"\"\"\n","\n","    #(‚âà 3 lines of code)\n","    # Apply exp() element-wise to x. Use np.exp(...).\n","    # x_exp = ...\n","\n","    # Create a vector x_sum that sums each row of x_exp. Use np.sum(..., axis = 1, keepdims = True).\n","    # x_sum = ...\n","\n","    # Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting.\n","    # s = ...\n","\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return s"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"e598fb22ddfec51bbdb6d08af1076cc5","grade":true,"grade_id":"cell-6f8e1f025948128c","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"Wl-CVdB2_XS4"},"outputs":[],"source":["t_x = np.array([[9, 2, 5, 0, 0],\n","                [7, 5, 0, 0 ,0]])\n","print(\"softmax(x) = \" + str(softmax(t_x)))\n","\n","softmax_test(softmax)"]},{"cell_type":"markdown","metadata":{"id":"8ROCpzGr_XS4"},"source":["#### üìù Remarques\n","- Si vous affichez les dimensions de `x_exp`, `x_sum` et `s` ci-dessus, puis relancez la cellule d‚Äô√©valuation,  \n","vous verrez que `x_sum` a la forme `(2, 1)` tandis que `x_exp` et `s` ont la forme `(2, 5)`.  \n","L'op√©ration **`x_exp / x_sum`** fonctionne gr√¢ce au **broadcasting** en Python.\n","\n","---\n","\n","üéâ **F√©licitations !**  \n","Vous avez maintenant une bonne compr√©hension de Python et de NumPy,  \n","et vous avez impl√©ment√© plusieurs fonctions utiles que vous utiliserez en **deep learning**.\n"]},{"cell_type":"markdown","metadata":{"id":"XxYeHyJO_XS4"},"source":["<font color='blue'>\n","<b>Ce qu‚Äôil faut retenir :</b>\n","\n","- `np.exp(x)` fonctionne pour tout tableau `np.array x` et applique la fonction exponentielle √† chaque √©l√©ment  \n","- La fonction sigmo√Øde et son gradient  \n","- `image2vector` est couramment utilis√© en deep learning  \n","- `np.reshape` est largement utilis√©. √Ä l‚Äôavenir, bien g√©rer les dimensions de vos matrices/vecteurs vous aidera √† √©viter de nombreux bugs  \n","- NumPy dispose de fonctions int√©gr√©es tr√®s efficaces  \n","- Le **broadcasting** est extr√™mement utile\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fZAcXrC7_XS4"},"source":["<a name='2'></a>\n","## 2 - Vectorisation ##\n","\n","En deep learning, vous travaillez avec des ensembles de donn√©es tr√®s volumineux.  \n","Par cons√©quent, une fonction qui n‚Äôest pas optimis√©e sur le plan computationnel peut devenir un √©norme goulot d‚Äô√©tranglement dans votre algorithme  \n","et entra√Æner un mod√®le extr√™mement lent √† ex√©cuter.\n","\n","Pour garantir l‚Äôefficacit√© de votre code, vous utiliserez la **vectorisation**.\n","\n","Par exemple, essayez d‚Äôobserver la diff√©rence entre les impl√©mentations suivantes :  \n","- produit scalaire (dot product)  \n","- produit ext√©rieur (outer product)  \n","- produit √©l√©ment par √©l√©ment (elementwise product)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nz6jK4rt_XS4"},"outputs":[],"source":["import time\n","\n","x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n","x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n","\n","### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n","tic = time.process_time()\n","dot = 0\n","\n","for i in range(len(x1)):\n","    dot += x1[i] * x2[i]\n","toc = time.process_time()\n","print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n","\n","### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n","tic = time.process_time()\n","outer = np.zeros((len(x1), len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n","\n","for i in range(len(x1)):\n","    for j in range(len(x2)):\n","        outer[i,j] = x1[i] * x2[j]\n","toc = time.process_time()\n","print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n","\n","### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n","tic = time.process_time()\n","mul = np.zeros(len(x1))\n","\n","for i in range(len(x1)):\n","    mul[i] = x1[i] * x2[i]\n","toc = time.process_time()\n","print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n","\n","### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n","W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n","tic = time.process_time()\n","gdot = np.zeros(W.shape[0])\n","\n","for i in range(W.shape[0]):\n","    for j in range(len(x1)):\n","        gdot[i] += W[i,j] * x1[j]\n","toc = time.process_time()\n","print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0to_mQl6_XS4"},"outputs":[],"source":["x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n","x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n","\n","### VECTORIZED DOT PRODUCT OF VECTORS ###\n","tic = time.process_time()\n","dot = np.dot(x1,x2)\n","toc = time.process_time()\n","print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n","\n","### VECTORIZED OUTER PRODUCT ###\n","tic = time.process_time()\n","outer = np.outer(x1,x2)\n","toc = time.process_time()\n","print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n","\n","### VECTORIZED ELEMENTWISE MULTIPLICATION ###\n","tic = time.process_time()\n","mul = np.multiply(x1,x2)\n","toc = time.process_time()\n","print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n","\n","### VECTORIZED GENERAL DOT PRODUCT ###\n","tic = time.process_time()\n","dot = np.dot(W,x1)\n","toc = time.process_time()\n","print (\"gdot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")"]},{"cell_type":"markdown","metadata":{"id":"zSUQvHge_XS4"},"source":["Comme vous l‚Äôavez sans doute remarqu√©, l‚Äôimpl√©mentation vectoris√©e est bien plus claire et efficace.  \n","Pour des vecteurs ou matrices de plus grande taille, les diff√©rences de temps d‚Äôex√©cution deviennent encore plus importantes.\n","\n","**Remarque** :  \n","`np.dot()` effectue une multiplication **matrice-matrice** ou **matrice-vecteur**.  \n","C‚Äôest diff√©rent de `np.multiply()` ou de l‚Äôop√©rateur `*` (√©quivalent √† `.*` en Matlab/Octave),  \n","qui r√©alise une multiplication **√©l√©ment par √©l√©ment** (ou **point par point**).\n","."]},{"cell_type":"markdown","metadata":{"id":"60dtzBNP_XS7"},"source":["<a name='2-1'></a>\n","### 2.1 Impl√©mentation des fonctions de perte L1 et L2\n","\n","<a name='ex-8'></a>\n","### Exercice 8 - L1\n","\n","Impl√©mentez la version vectoris√©e avec NumPy de la perte L1 (L1 loss).  \n","Vous pouvez utiliser la fonction `abs(x)` (valeur absolue de `x`).\n","\n","**Rappel** :\n","- La fonction de perte est utilis√©e pour √©valuer les performances de votre mod√®le.  \n","Plus la perte est √©lev√©e, plus vos pr√©dictions $( \\hat{y} $) sont diff√©rentes des vraies valeurs ($ y $).  \n","En deep learning, vous utilisez des algorithmes d‚Äôoptimisation comme la **descente de gradient** pour entra√Æner votre mod√®le et **minimiser le co√ªt**.\n","\n","- La perte L1 est d√©finie par :\n","$\n","L_1(\\hat{y}, y) = \\sum_{i=0}^{m-1} \\left| y^{(i)} - \\hat{y}^{(i)} \\right| \\tag{6}\n","$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"2c496fe0b5fb6fe1580162305cf97387","grade":false,"grade_id":"cell-410accbd4d9a1fc2","locked":false,"schema_version":3,"solution":true,"task":false},"id":"KuWOniwI_XS7"},"outputs":[],"source":["# GRADED FUNCTION: L1\n","\n","def L1(yhat, y):\n","    \"\"\"\n","    Arguments:\n","    yhat -- vector of size m (predicted labels)\n","    y -- vector of size m (true labels)\n","\n","    Returns:\n","    loss -- the value of the L1 loss function defined above\n","    \"\"\"\n","\n","    #(‚âà 1 line of code)\n","    # loss =\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"7435251c8f0959006b7034fd1eb9a2d3","grade":true,"grade_id":"cell-44ac3b50c1fba7a0","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"v6LHnxGu_XS7"},"outputs":[],"source":["yhat = np.array([.9, 0.2, 0.1, .4, .9])\n","y = np.array([1, 0, 0, 1, 1])\n","print(\"L1 = \" + str(L1(yhat, y)))\n","\n","L1_test(L1)"]},{"cell_type":"markdown","metadata":{"id":"_8J9ltHQ_XS7"},"source":["<a name='ex-9'></a>\n","### Exercice 9 - Norme L2\n","Impl√©mentez la version vectoris√©e avec NumPy de la perte L2. Il existe plusieurs fa√ßons de calculer la perte L2, mais vous pourriez trouver la fonction `np.dot()` utile. Pour rappel, si $x = [x_1, x_2, ..., x_n]$, alors `np.dot(x, x)` = $\\sum_{j=0}^n x_j^{2}$.\n","\n","- La perte L2 est d√©finie comme :  \n","$$\\begin{align*} & L_2(\\hat{y}, y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$\n","\n","**Conseils** :  \n","1. Utilisez les op√©rations vectorielles de NumPy pour √©viter les boucles explicites.  \n","2. `np.dot()` peut aider √† calculer la somme des carr√©s efficacement.  \n","3. La diff√©rence √©l√©ment par √©l√©ment entre `y` et `≈∑` peut √™tre calcul√©e directement par `(y - ≈∑)`.  \n","\n","**Exemple de sortie attendue** :  \n","```python\n"," Si y = np.array([1, 2, 3]) et ≈∑ = np.array([1.1, 2.2, 3.3])\n","L2 ‚âà (0.1¬≤ + 0.2¬≤ + 0.3¬≤) = 0.14\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"d806d7037061895561c70f6abb03380e","grade":false,"grade_id":"cell-a2624d0db4d22322","locked":false,"schema_version":3,"solution":true,"task":false},"id":"raQSMAkW_XS7"},"outputs":[],"source":["# GRADED FUNCTION: L2\n","\n","def L2(yhat, y):\n","    \"\"\"\n","    Arguments:\n","    yhat -- vector of size m (predicted labels)\n","    y -- vector of size m (true labels)\n","\n","    Returns:\n","    loss -- the value of the L2 loss function defined above\n","    \"\"\"\n","\n","    #(‚âà 1 line of code)\n","    # loss = ...\n","    # YOUR CODE STARTS HERE\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"ef616282fe941f332052dbb8641e9aa8","grade":true,"grade_id":"cell-e7809ad65b5fe0ab","locked":true,"points":10,"schema_version":3,"solution":false,"task":false},"id":"yd9tdFQG_XS7"},"outputs":[],"source":["yhat = np.array([.9, 0.2, 0.1, .4, .9])\n","y = np.array([1, 0, 0, 1, 1])\n","\n","print(\"L2 = \" + str(L2(yhat, y)))\n","\n","L2_test(L2)"]},{"cell_type":"markdown","metadata":{"id":"iDOuG6as_XS8"},"source":["üéâ **F√©licitations pour avoir termin√© cet exercice !**  \n","\n","Nous esp√©rons que cet exercice d‚Äô√©chauffement vous aidera √† bien aborder les prochains devoirs,  \n","qui seront encore plus passionnants et stimulants !\n"]},{"cell_type":"markdown","metadata":{"id":"SdyNcqHS_XS8"},"source":["<font color='blue'>\n","<b>Ce qu‚Äôil faut retenir :</b>\n","\n","- La vectorisation est tr√®s importante en deep learning. Elle am√©liore l‚Äôefficacit√© computationnelle et rend le code plus clair.  \n","- Vous avez r√©vis√© les fonctions de perte L1 et L2.  \n","- Vous √™tes d√©sormais familiaris√© avec de nombreuses fonctions NumPy telles que :  \n","  `np.sum`, `np.dot`, `np.multiply`, `np.maximum`, etc.\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}