{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c99b31",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Exercise: Fine-Tuning BERT on SST-2 for Sentiment Analysis\n",
    "Fill in the missing sections marked with `# TODO` to complete each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d2dbe",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Install libraries and import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49df5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate scikit-learn --quiet\n",
    "\n",
    "# TODO: Import the following:\n",
    "# torch\n",
    "# BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments from transformers\n",
    "# load_dataset from datasets\n",
    "# numpy as np\n",
    "# evaluate\n",
    "# classification_report from sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ec388",
   "metadata": {},
   "source": [
    "## 2. Load SST-2 Dataset\n",
    "Use the GLUE 'sst2' configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the SST-2 dataset\n",
    "dataset = \n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca00df",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "Tokenize sentences with `max_length=128`, `truncation=True`, `padding='max_length'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    # TODO: Tokenize the 'sentence' field\n",
    "    return {}\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa98b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set format to PyTorch tensors for ['input_ids','attention_mask','label']\n",
    "# Hint: tokenized_datasets.set_format(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5ab58",
   "metadata": {},
   "source": [
    "## 4. Model Initialization\n",
    "Load BERT for sequence classification with 2 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize model\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379a79a",
   "metadata": {},
   "source": [
    "## 5. Training Arguments\n",
    "Configure `TrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8af301",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_sst2',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs_sst2',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172a00",
   "metadata": {},
   "source": [
    "## 6. Metrics\n",
    "Define `compute_metrics` using accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f41b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # TODO: Compute predictions and return accuracy\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45f1b3",
   "metadata": {},
   "source": [
    "## 7. Training\n",
    "Initialize `Trainer` and call `.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b144fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'].shuffle(seed=42).select(range(5000)),\n",
    "    eval_dataset=tokenized_datasets['validation'].select(range(1000)),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6bda74",
   "metadata": {},
   "source": [
    "## 8. Evaluation\n",
    "Generate predictions and print a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use trainer.predict on validation set\n",
    "# and print classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1be76",
   "metadata": {},
   "source": [
    "## 9. Save Model\n",
    "Save model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save to './finetuned-bert-sst2-exercise'\n",
    "model.save_pretrained('')\n",
    "tokenizer.save_pretrained('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bfe30",
   "metadata": {},
   "source": [
    "## 10. Inference\n",
    "Write `predict_sentiment` to return 'positive' or 'negative'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # TODO: Tokenize and run model\n",
    "    return \n",
    "\n",
    "print(predict_sentiment('An absolutely wonderful film.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bed298",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Complete all TODOs to finish the fine-tuning exercise. Good luck!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}