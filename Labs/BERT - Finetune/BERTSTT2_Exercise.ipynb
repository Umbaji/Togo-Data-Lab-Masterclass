{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dac412c",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Exercise: Building BERTSTT2 with DistilBERT\n",
    "Fill in the missing parts marked with `# TODO` to construct and use your own seq2seq model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b775fb5",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Install dependencies and prepare imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install transformers torch --quiet\n",
    "\n",
    "# TODO: Import the following\n",
    "# - DistilBertConfig, EncoderDecoderConfig, EncoderDecoderModel, DistilBertTokenizerFast\n",
    "#   from transformers\n",
    "# - torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cab457",
   "metadata": {},
   "source": [
    "## 2. Tokenizer & Configuration\n",
    "Create tokenizer and encoder/decoder configs; combine into a seq2seq config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# TODO: Load encoder_config from 'distilbert-base-uncased'\n",
    "encoder_config = \n",
    "\n",
    "# TODO: Load decoder_config from 'distilbert-base-uncased' with cross-attention enabled\n",
    "decoder_config = \n",
    "\n",
    "# TODO: Combine configs into seq2seq_config using EncoderDecoderConfig.from_encoder_decoder_configs\n",
    "seq2seq_config = \n",
    "\n",
    "# TODO: Tie vocab_size, pad_token_id, decoder_start_token_id, eos_token_id from tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541e38a",
   "metadata": {},
   "source": [
    "## 3. Model Instantiation\n",
    "Instantiate the EncoderDecoderModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec576f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create model from seq2seq_config\n",
    "model = \n",
    "\n",
    "# Check your model structure\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468bea7",
   "metadata": {},
   "source": [
    "## 4. Generation Example\n",
    "Encode input text and generate an output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82509e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input text\n",
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# TODO: Tokenize input_text to get input_ids tensor\n",
    "input_ids = \n",
    "\n",
    "# TODO: Generate using model.generate (e.g., max_length=30)\n",
    "generated_ids = \n",
    "\n",
    "# TODO: Decode and print the generated result\n",
    "print('Generated:', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baefce",
   "metadata": {},
   "source": [
    "## 5. Save the Model\n",
    "Persist both model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save model and tokenizer to './BERTSTT2_exercise'\n",
    "model.save_pretrained('')\n",
    "tokenizer.save_pretrained('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce889c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Prepare paired data and fine-tune with Seq2SeqTrainer.\n",
    "2. Evaluate generation quality (e.g., BLEU, ROUGE).\n",
    "3. Swap in other pre-trained backbones or adjust hyperparameters."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}